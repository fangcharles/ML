{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic comments\n",
    "\n",
    "This notebook takes you though a complete iteration of Machine Learning Assignment 1 - Toxic comments. The assignment details (including links to download the data) can be found [here](https://docs.google.com/document/d/1WGYw99e5q6j5V0Zrf2HveagU6URt_kVvdR8B9HYQ99E/edit?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!!! Make sure you are using `BinaryClassificationPerformance` v1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for feature building and extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 5 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False, ngram_range=(1,2), stop_words='english')       \n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    # submission condition is test: what's the diff between test and not test here?  \n",
    "    # 'fitted_transformations.append' vs. '.transform'.  Why in the test condition does transform the data\n",
    "    # \"fit\" computes the mean and std to be used for later scaling. (just a computation) \n",
    "    # \"transform\" uses a previously computed mean and std to autoscale the data\n",
    "        \n",
    "    if (not test):\n",
    "        chv = HashingVectorizer(n_features=2 ** 14, alternate_sign=False, analyzer='char_wb', ngram_range=(2,4))\n",
    "        X_chv = chv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations.append(chv)\n",
    "        print(\"Shape of HashingVectorizer char n_gram X:\")\n",
    "        print(X_chv.shape)\n",
    "    else:\n",
    "        X_chv = fitted_transformations[1].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer char n_gram X:\")\n",
    "        print(X_chv.shape)\n",
    "    \n",
    "#     X_cv = hstack([X_hv, X_chv])\n",
    "#     print(\"Shape of Vectorizer combined X:\")\n",
    "#     print(X_cv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "#     if (not test):\n",
    "#         transformer = TfidfTransformer()\n",
    "#         X_tfidf = transformer.fit_transform(X_cv)\n",
    "#         fitted_transformations.append(transformer)\n",
    "#     else:\n",
    "#         X_tfidf = fitted_transformations[1].transform(X_cv)\n",
    "    \n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[2].transform(X_hv)\n",
    "\n",
    "    #    \n",
    "    if (not test):\n",
    "        transformer_chv = TfidfTransformer()\n",
    "        X_tfidf_chv = transformer_chv.fit_transform(X_chv)\n",
    "        fitted_transformations.append(transformer_chv)\n",
    "    else:\n",
    "        X_tfidf_chv = fitted_transformations[3].transform(X_chv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "\n",
    "    # what does the form toxic_data['comment_text'] mean?\n",
    "    toxic_data['char_count'] = toxic_data['comment_text'].str.len()\n",
    "    toxic_data['Caps_count'] = toxic_data['comment_text'].str.count(r'[A-Z]')\n",
    "    toxic_data['Caps_ratio'] = pow((toxic_data['Caps_count']+1)/toxic_data['char_count'], 3)\n",
    "    \n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['char_ratio'] = toxic_data['char_count']/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['punc_count_p'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "    toxic_data['punc_count_exc'] = toxic_data['comment_text'].str.count(\"\\!\")\n",
    "    toxic_data['punc_count_q'] = toxic_data['comment_text'].str.count(\"\\?\")\n",
    "    \n",
    "    toxic_data['punc_count'] = toxic_data['punc_count_p'] + toxic_data['punc_count_exc'] + toxic_data['punc_count_q']\n",
    "    toxic_data['punc_ratio'] = toxic_data['punc_count']/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['Capsword_ratio'] = (toxic_data['Caps_count'] + toxic_data['punc_count'])/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['spaces_count'] = toxic_data['comment_text'].str.count(\" \")\n",
    "    toxic_data['spaces_ratio'] = toxic_data['spaces_count']/toxic_data['char_count']\n",
    "    toxic_data['spaceswords_ratio'] = toxic_data['spaces_count']/toxic_data['word_count']\n",
    "    \n",
    "    # count the number of consecutive caps letters\n",
    "    toxic_data['consCaps_count'] = toxic_data['comment_text'].str.count(r'[A-Z]{3}')\n",
    "    toxic_data['consCaps_ratio'] = toxic_data['consCaps_count']/toxic_data['char_count']\n",
    "    toxic_data['consCapsword_ratio'] = toxic_data['consCaps_count']/toxic_data['word_count']\n",
    "    \n",
    "    # current count: 17 quant features\n",
    "    X_quant_features = toxic_data[[\"consCapsword_ratio\", \"consCaps_ratio\", \"consCaps_count\", \"spaceswords_ratio\", \"spaces_ratio\", \"spaces_count\", \"char_count\", \"Caps_count\", \"Caps_ratio\", \"word_count\", \"char_ratio\", \"punc_count_p\", \"punc_count_exc\", \"punc_count_q\", \"punc_count\", \"punc_ratio\", \"Capsword_ratio\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "#     X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_combined = hstack([X_tfidf, X_tfidf_chv, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X = fitted_transformations[4].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "\n",
    "#     # polynomialregression\n",
    "#     if (not test):\n",
    "#         poly = PolynomialFeatures(degree=2, interaction_only=True, order='F')\n",
    "#         X = poly.fit_transform(X_matrix)\n",
    "#         fitted_transformations.append(poly)\n",
    "#         print(X.shape)\n",
    "#         y = toxic_data['any_toxic']\n",
    "#     else:\n",
    "#         X = fitted_transformations[4].transform(X_matrix)\n",
    "#         print(X.shape)\n",
    "    \n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2\n",
    "def process_raw_data2(fn, my_random_seed, test=False):\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 5 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    if (not test): # fit_transform()\n",
    "        hv2 = HashingVectorizer(n_features=2 ** 14, alternate_sign=False, \n",
    "                               ngram_range=(1,2), token_pattern=r'\\b\\w+\\b', \n",
    "                               stop_words='english')       \n",
    "        X_hv2 = hv2.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations2.append(hv2)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv2.shape)\n",
    "    else: # transform() \n",
    "        X_hv2 = fitted_transformations2[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv2.shape)\n",
    "        \n",
    "    if (not test):\n",
    "        chv2 = HashingVectorizer(n_features=2 ** 14, alternate_sign=False, \n",
    "                                analyzer='char_wb', ngram_range=(2,4))\n",
    "        X_chv2 = chv2.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations2.append(chv2)\n",
    "        print(\"Shape of HashingVectorizer char n_gram X:\")\n",
    "        print(X_chv2.shape)\n",
    "    else:\n",
    "        X_chv2 = fitted_transformations2[1].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer char n_gram X:\")\n",
    "        print(X_chv2.shape)\n",
    "    \n",
    "    if (not test):\n",
    "        transformer2 = TfidfTransformer()\n",
    "        X_tfidf2 = transformer2.fit_transform(X_hv2)\n",
    "        fitted_transformations2.append(transformer2)\n",
    "    else:\n",
    "        X_tfidf2 = fitted_transformations2[2].transform(X_hv2)\n",
    "\n",
    "    # character n-grams   \n",
    "    if (not test):\n",
    "        transformer_chv2 = TfidfTransformer()\n",
    "        X_tfidf_chv2 = transformer_chv2.fit_transform(X_chv2)\n",
    "        fitted_transformations2.append(transformer_chv2)\n",
    "    else:\n",
    "        X_tfidf_chv2 = fitted_transformations2[3].transform(X_chv2)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    toxic_data['char_count'] = toxic_data['comment_text'].str.len()\n",
    "    toxic_data['Caps_count'] = toxic_data['comment_text'].str.count(r'[A-Z]')\n",
    "    toxic_data['Caps_ratio'] = pow((toxic_data['Caps_count']+1)/toxic_data['char_count'], 3)\n",
    "    \n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['char_ratio'] = toxic_data['char_count']/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['punc_count_p'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "    toxic_data['punc_count_exc'] = toxic_data['comment_text'].str.count(\"\\!\")\n",
    "    toxic_data['punc_count_q'] = toxic_data['comment_text'].str.count(\"\\?\")\n",
    "    toxic_data['punc_count_c'] = toxic_data['comment_text'].str.count(\"\\,\")\n",
    "    toxic_data['punc_count_a'] = toxic_data['comment_text'].str.count(\"\\*\")\n",
    "    toxic_data['punc_count_s'] = toxic_data['comment_text'].str.count(\"\\;\")\n",
    "    \n",
    "    toxic_data['punc_count'] = toxic_data['punc_count_s'] + toxic_data['punc_count_a'] + toxic_data['punc_count_c'] + toxic_data['punc_count_p'] + toxic_data['punc_count_exc'] + toxic_data['punc_count_q']\n",
    "    toxic_data['punc_ratio'] = toxic_data['punc_count']/toxic_data['word_count']\n",
    "    toxic_data['punc_exc_ratio'] = (toxic_data['punc_count_exc']+0.1) / (toxic_data['punc_count']+0.1)\n",
    "    toxic_data['punc_q_ratio'] = (toxic_data['punc_count_q']+0.1) / (toxic_data['punc_count']+0.1)\n",
    "    \n",
    "    toxic_data['Capsword_ratio'] = (toxic_data['Caps_count'] + toxic_data['punc_count'])/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['spaces_count'] = toxic_data['comment_text'].str.count(\" \")\n",
    "    toxic_data['spaces_ratio'] = toxic_data['spaces_count']/toxic_data['char_count']\n",
    "    toxic_data['spaceswords_ratio'] = toxic_data['spaces_count']/toxic_data['word_count']\n",
    "    \n",
    "    # count the number of consecutive caps letters\n",
    "    toxic_data['consCaps_count'] = toxic_data['comment_text'].str.count(r'[A-Z]{3}')\n",
    "    toxic_data['consCaps_ratio'] = toxic_data['consCaps_count']/toxic_data['char_count']\n",
    "    toxic_data['consCapsword_ratio'] = toxic_data['consCaps_count']/toxic_data['word_count']\n",
    "    \n",
    "    # current count: 22 quant features\n",
    "    X_quant_features = toxic_data[[\"consCaps_count\", \"consCaps_ratio\", \"consCapsword_ratio\", \"punc_q_ratio\", \"punc_exc_ratio\", \"punc_count_s\", \"punc_count_a\", \"punc_count_c\", \"spaceswords_ratio\", \"spaces_ratio\", \"spaces_count\", \"char_count\", \"Caps_count\", \"Caps_ratio\", \"word_count\", \"char_ratio\", \"punc_count_p\", \"punc_count_exc\", \"punc_count_q\", \"punc_count\", \"punc_ratio\", \"Capsword_ratio\"]]\n",
    "    # for specific quant_feat\n",
    "#     X_quant_features = toxic_data[[\"char_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "        \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    # hstack wo char n-grams\n",
    "#     X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_combined2 = hstack([X_tfidf2, X_tfidf_chv2, X_quant_features_csr])\n",
    "    X_matrix2 = csr_matrix(X_combined2) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix2.shape)\n",
    "     \n",
    "        \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc2 = StandardScaler(with_mean=False)\n",
    "        X2 = sc2.fit_transform(X_matrix2)\n",
    "        fitted_transformations2.append(sc2)\n",
    "        print(X2.shape)\n",
    "        y2 = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X2 = fitted_transformations2[4].transform(X_matrix2)\n",
    "        print(X2.shape)\n",
    "\n",
    "\n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X2_submission_test = X2\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X2_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X2_submission_test)\n",
    "    else: \n",
    "        X2_train, X2_test, y2_train, y2_test, X2_raw_train, X2_raw_test = train_test_split(X2, y2, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X2_train.shape)\n",
    "        print(X2_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y2_train.shape)\n",
    "        print(y2_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X2_raw_train.shape)\n",
    "        print(X2_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X2_train, X2_test, y2_train, y2_test, X2_raw_train, X2_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test sets from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 5 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "Shape of HashingVectorizer char n_gram X:\n",
      "(159571, 16384)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   consCapsword_ratio  consCaps_ratio  consCaps_count  spaceswords_ratio  \\\n",
      "0            0.023810        0.003788               1           0.976190   \n",
      "1            0.055556        0.008929               1           0.944444   \n",
      "2            0.000000        0.000000               0           0.976190   \n",
      "3            0.000000        0.000000               0           0.991071   \n",
      "4            0.000000        0.000000               0           0.923077   \n",
      "5            0.000000        0.000000               0           0.916667   \n",
      "6            1.250000        0.227273              10           0.875000   \n",
      "7            0.000000        0.000000               0           0.952381   \n",
      "8            0.000000        0.000000               0           0.987952   \n",
      "9            0.000000        0.000000               0           0.916667   \n",
      "\n",
      "   spaces_ratio  spaces_count  char_count  Caps_count  Caps_ratio  word_count  \\\n",
      "0      0.155303            41         264          17    0.000317          42   \n",
      "1      0.151786            17         112           8    0.000519          18   \n",
      "2      0.175966            41         233           4    0.000010          42   \n",
      "3      0.178457           111         622          11    0.000007         112   \n",
      "4      0.179104            12          67           2    0.000090          13   \n",
      "5      0.169231            11          65           1    0.000029          12   \n",
      "6      0.159091             7          44          37    0.644159           8   \n",
      "7      0.173913            20         115           4    0.000082          21   \n",
      "8      0.173729            82         472           7    0.000005          83   \n",
      "9      0.157143            11          70           2    0.000079          12   \n",
      "\n",
      "   char_ratio  punc_count_p  punc_count_exc  punc_count_q  punc_count  \\\n",
      "0    6.285714             5               0             1           6   \n",
      "1    6.222222             2               1             0           3   \n",
      "2    5.547619             3               0             0           3   \n",
      "3    5.553571             3               0             0           3   \n",
      "4    5.153846             1               0             1           2   \n",
      "5    5.416667             1               0             0           1   \n",
      "6    5.500000             0               0             0           0   \n",
      "7    5.476190             2               0             0           2   \n",
      "8    5.686747             7               0             1           8   \n",
      "9    5.833333             0               0             0           0   \n",
      "\n",
      "   punc_ratio  Capsword_ratio  \n",
      "0    0.142857        0.547619  \n",
      "1    0.166667        0.611111  \n",
      "2    0.071429        0.166667  \n",
      "3    0.026786        0.125000  \n",
      "4    0.153846        0.307692  \n",
      "5    0.083333        0.166667  \n",
      "6    0.000000        4.625000  \n",
      "7    0.095238        0.285714  \n",
      "8    0.096386        0.180723  \n",
      "9    0.000000        0.166667  \n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 147473)\n",
      "(159571, 147473)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 147473)\n",
      "(31915, 147473)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 26)\n",
      "(31915, 26)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "5\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='/Users/Charles/Desktop/ML/A1/toxiccomments_train.csv', my_random_seed=36)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 5 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 16384)\n",
      "Shape of HashingVectorizer char n_gram X:\n",
      "(159571, 16384)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   consCaps_count  consCaps_ratio  consCapsword_ratio  punc_q_ratio  \\\n",
      "0               1        0.003788            0.023810      0.154930   \n",
      "1               1        0.008929            0.055556      0.019608   \n",
      "2               0        0.000000            0.000000      0.024390   \n",
      "3               0        0.000000            0.000000      0.019608   \n",
      "4               0        0.000000            0.000000      0.268293   \n",
      "5               0        0.000000            0.000000      0.047619   \n",
      "6              10        0.227273            1.250000      1.000000   \n",
      "7               0        0.000000            0.000000      0.032258   \n",
      "8               0        0.000000            0.000000      0.108911   \n",
      "9               0        0.000000            0.000000      1.000000   \n",
      "\n",
      "   punc_exc_ratio  punc_count_s  punc_count_a  punc_count_c  \\\n",
      "0        0.014085             0             0             1   \n",
      "1        0.215686             0             0             2   \n",
      "2        0.024390             0             0             1   \n",
      "3        0.019608             0             0             2   \n",
      "4        0.024390             0             0             2   \n",
      "5        0.047619             0             0             1   \n",
      "6        1.000000             0             0             0   \n",
      "7        0.032258             0             0             1   \n",
      "8        0.009901             0             0             2   \n",
      "9        1.000000             0             0             0   \n",
      "\n",
      "   spaceswords_ratio  spaces_ratio  ...  Caps_count  Caps_ratio  word_count  \\\n",
      "0           0.976190      0.155303  ...          17    0.000317          42   \n",
      "1           0.944444      0.151786  ...           8    0.000519          18   \n",
      "2           0.976190      0.175966  ...           4    0.000010          42   \n",
      "3           0.991071      0.178457  ...          11    0.000007         112   \n",
      "4           0.923077      0.179104  ...           2    0.000090          13   \n",
      "5           0.916667      0.169231  ...           1    0.000029          12   \n",
      "6           0.875000      0.159091  ...          37    0.644159           8   \n",
      "7           0.952381      0.173913  ...           4    0.000082          21   \n",
      "8           0.987952      0.173729  ...           7    0.000005          83   \n",
      "9           0.916667      0.157143  ...           2    0.000079          12   \n",
      "\n",
      "   char_ratio  punc_count_p  punc_count_exc  punc_count_q  punc_count  \\\n",
      "0    6.285714             5               0             1           7   \n",
      "1    6.222222             2               1             0           5   \n",
      "2    5.547619             3               0             0           4   \n",
      "3    5.553571             3               0             0           5   \n",
      "4    5.153846             1               0             1           4   \n",
      "5    5.416667             1               0             0           2   \n",
      "6    5.500000             0               0             0           0   \n",
      "7    5.476190             2               0             0           3   \n",
      "8    5.686747             7               0             1          10   \n",
      "9    5.833333             0               0             0           0   \n",
      "\n",
      "   punc_ratio  Capsword_ratio  \n",
      "0    0.166667        0.571429  \n",
      "1    0.277778        0.722222  \n",
      "2    0.095238        0.190476  \n",
      "3    0.044643        0.142857  \n",
      "4    0.307692        0.461538  \n",
      "5    0.166667        0.250000  \n",
      "6    0.000000        4.625000  \n",
      "7    0.142857        0.333333  \n",
      "8    0.120482        0.204819  \n",
      "9    0.000000        0.166667  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 32790)\n",
      "(159571, 32790)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 32790)\n",
      "(31915, 32790)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 31)\n",
      "(31915, 31)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "5\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# X2\n",
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations2 = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X2_train, X2_test, y2_train, y2_test, X2_raw_train, X2_raw_test = process_raw_data2(fn='/Users/Charles/Desktop/ML/A1/toxiccomments_train.csv', my_random_seed=36)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit (and tune) Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(ols_performance_train.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(ols_performance_train.performance_measures['FP'] / ols_performance_train.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(ols_performance_train.performance_measures['TP'] / ols_performance_train.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12162, 'TN': 113071, 'FP': 1634, 'FN': 789, 'Accuracy': 0.9810193018737858, 'Precision': 0.8815598724267903, 'Recall': 0.9390780634700023, 'desc': 'svm_train'}\n",
      "False Positive Rate:\n",
      "0.014245237783880389\n",
      "True Positive Rate:\n",
      "0.9390780634700023\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(svm_performance_train.performance_measures['FP'] / svm_performance_train.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(svm_performance_train.performance_measures['TP'] / svm_performance_train.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 9587, 'TN': 112736, 'FP': 1969, 'FN': 3364, 'Accuracy': 0.958223663595914, 'Precision': 0.8296123226029768, 'Recall': 0.740251718014053, 'desc': 'lgs_train'}\n",
      "False Positive Rate:\n",
      "0.017165773070049257\n",
      "True Positive Rate:\n",
      "0.740251718014053\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log')\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(lgs_performance_train.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(lgs_performance_train.performance_measures['FP'] / lgs_performance_train.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(lgs_performance_train.performance_measures['TP'] / lgs_performance_train.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# lgr\n",
    "from sklearn import linear_model\n",
    "lgr = linear_model.LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "lgr.fit(X2_train, y2_train)\n",
    "\n",
    "lgr_performance_train = BinaryClassificationPerformance(lgr.predict(X2_train), y2_train, 'lgr_train')\n",
    "lgr_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 878 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB(alpha=0.01)\n",
    "nbs.fit(X2_train, y2_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X2_train), y2_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 950 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Complement Naive Bayes\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "cnb = ComplementNB(alpha=0.00001, norm=True)\n",
    "cnb.fit(X2_train, y2_train)\n",
    "\n",
    "cnb_performance_train = BinaryClassificationPerformance(cnb.predict(X2_train), y2_train, 'cnb_train')\n",
    "cnb_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 8107, 'TN': 113326, 'FP': 1379, 'FN': 4844, 'Accuracy': 0.9512518017171148, 'Precision': 0.8546278726544381, 'Recall': 0.6259748281985947, 'desc': 'prc_train'}\n",
      "False Positive Rate:\n",
      "0.012022143760080206\n",
      "True Positive Rate:\n",
      "0.6259748281985947\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X_train, y_train)\n",
    "\n",
    "prc_performance_train = BinaryClassificationPerformance(prc.predict(X_train), y_train, 'prc_train')\n",
    "prc_performance_train.compute_measures()\n",
    "print(prc_performance_train.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(prc_performance_train.performance_measures['FP'] / prc_performance_train.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(prc_performance_train.performance_measures['TP'] / prc_performance_train.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# multilayer perceptron\n",
    "# too much runtime\n",
    "from sklearn import neural_network\n",
    "mlp = neural_network.MLPClassifier(hidden_layer_sizes=(2, 4))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp_performance_train = BinaryClassificationPerformance(mlp.predict(X_train), y_train, 'mlp_train')\n",
    "mlp_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12455, 'TN': 105851, 'FP': 8854, 'FN': 496, 'Accuracy': 0.9267562825092436, 'Precision': 0.5844948143976724, 'Recall': 0.9617017990888734, 'desc': 'rdg'}\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier(alpha=25, normalize=True, solver='sag')\n",
    "rdg.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train = BinaryClassificationPerformance(rdg.predict(X_train), y_train, 'rdg')\n",
    "rdg_performance_train.compute_measures()\n",
    "print(rdg_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12947, 'TN': 96292, 'FP': 18413, 'FN': 4, 'Accuracy': 0.855729460424892, 'Precision': 0.41285076530612247, 'Recall': 0.9996911435410393, 'desc': 'rdg_5'}\n",
      "Wall time: 48.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_5 = linear_model.RidgeClassifier(alpha=5, normalize=True, solver='sag')\n",
    "rdg_5.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_5 = BinaryClassificationPerformance(rdg_5.predict(X_train), y_train, 'rdg_5')\n",
    "rdg_performance_train_5.compute_measures()\n",
    "print(rdg_performance_train_5.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_7p5 = linear_model.RidgeClassifier(alpha=7.5, normalize=True, solver='sag')\n",
    "rdg_7p5.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_7p5 = BinaryClassificationPerformance(rdg_7p5.predict(X_train), y_train, 'rdg_7p5')\n",
    "rdg_performance_train_7p5.compute_measures()\n",
    "print(rdg_performance_train_7p5.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12918, 'TN': 100553, 'FP': 14152, 'FN': 33, 'Accuracy': 0.8888810553362161, 'Precision': 0.4772072404876247, 'Recall': 0.9974519342135743, 'desc': 'rdg_10'}\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_10 = linear_model.RidgeClassifier(alpha=10, normalize=True, solver='sag')\n",
    "rdg_10.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_10 = BinaryClassificationPerformance(rdg_10.predict(X_train), y_train, 'rdg_10')\n",
    "rdg_performance_train_10.compute_measures()\n",
    "print(rdg_performance_train_10.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12796, 'TN': 102976, 'FP': 11729, 'FN': 155, 'Accuracy': 0.9069060600363477, 'Precision': 0.5217533129459735, 'Recall': 0.9880318122152729, 'desc': 'rdg_15'}\n",
      "Wall time: 45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_15 = linear_model.RidgeClassifier(alpha=15, normalize=True, solver='sag')\n",
    "rdg_15.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_15 = BinaryClassificationPerformance(rdg_15.predict(X_train), y_train, 'rdg_15')\n",
    "rdg_performance_train_15.compute_measures()\n",
    "print(rdg_performance_train_15.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12653, 'TN': 104604, 'FP': 10101, 'FN': 298, 'Accuracy': 0.9185388857554678, 'Precision': 0.5560780522106004, 'Recall': 0.976990193807428, 'desc': 'rdg_20'}\n",
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_20 = linear_model.RidgeClassifier(alpha=20, normalize=True, solver='sag')\n",
    "rdg_20.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_20 = BinaryClassificationPerformance(rdg_20.predict(X_train), y_train, 'rdg_20')\n",
    "rdg_performance_train_20.compute_measures()\n",
    "print(rdg_performance_train_20.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12455, 'TN': 105852, 'FP': 8853, 'FN': 496, 'Accuracy': 0.9267641160619164, 'Precision': 0.5845222451661348, 'Recall': 0.9617017990888734, 'desc': 'rdg_25'}\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_25 = linear_model.RidgeClassifier(alpha=25, normalize=True, solver='sag')\n",
    "rdg_25.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_25 = BinaryClassificationPerformance(rdg_25.predict(X_train), y_train, 'rdg_25')\n",
    "rdg_performance_train_25.compute_measures()\n",
    "print(rdg_performance_train_25.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12242, 'TN': 106781, 'FP': 7924, 'FN': 709, 'Accuracy': 0.9323729397756471, 'Precision': 0.6070613904591887, 'Recall': 0.9452551926492163, 'desc': 'rdg_30'}\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_30 = linear_model.RidgeClassifier(alpha=30, normalize=True, solver='sag')\n",
    "rdg_30.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_30 = BinaryClassificationPerformance(rdg_30.predict(X_train), y_train, 'rdg_30')\n",
    "rdg_performance_train_30.compute_measures()\n",
    "print(rdg_performance_train_30.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    943\u001b[0m                              compute_sample_weight(self.class_weight, y))\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sag'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_n_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 return_intercept=True, check_input=False)\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[1;31m# add the offset which was subtracted by _preprocess_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my_offset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36m_ridge_regression\u001b[1;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input)\u001b[0m\n\u001b[0;32m    487\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'squared'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 init, is_saga=solver == 'saga')\n\u001b[0m\u001b[0;32m    490\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_intercept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                 \u001b[0mcoef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    324\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                             verbose)\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_35 = linear_model.RidgeClassifier(alpha=35, normalize=True, solver='sag')\n",
    "rdg_35.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_35 = BinaryClassificationPerformance(rdg_35.predict(X_train), y_train, 'rdg_35')\n",
    "rdg_performance_train_35.compute_measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_40 = linear_model.RidgeClassifier(alpha=40, normalize=True, solver='sag')\n",
    "rdg_40.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_40 = BinaryClassificationPerformance(rdg_40.predict(X_train), y_train, 'rdg_40')\n",
    "rdg_performance_train_40.compute_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 0, 'TN': 114705, 'FP': 0, 'FN': 12951, 'Accuracy': 0.8985476593344613, 'Precision': nan, 'Recall': 0.0, 'desc': 'rdf_train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charles\\Desktop\\ML\\A1\\my_measures.py:25: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  self.performance_measures['Precision'] = self.performance_measures['TP'] / (self.performance_measures['TP'] + self.performance_measures['FP'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# manipulate max_depth\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "rdf_performance_train = BinaryClassificationPerformance(rdf.predict(X_train), y_train, 'rdf_train')\n",
    "rdf_performance_train.compute_measures()\n",
    "print(rdf_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fits = [ols_performance_train, svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fits = [rdg_performance_train, rdg_performance_train_1, rdg_performance_train_2, rdg_performance_train_7, rdg_performance_train_9, rdg_performance_train_13, rdg_performance_train_19]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0.000415, 0.00043, 0.961, .963])\n",
    "plt.title('ROC plot Ridge Regression: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at reviews based on their classification\n",
    "\n",
    "Let's say we decide that Ordinary Least Squares (OLS) Regression is the best model for generalization. Let's take a look at some of the reviews and try to make a (subjective) determination of whether it's generalizing well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look at some false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_predictions = nbs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(nbs_predictions)):\n",
    "    if (nbs_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true positives\n",
    "\n",
    "print(\"Examples of true positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(nbs_predictions)):\n",
    "    if (ols_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 1):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "\n",
    "print(\"Examples of false negatives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(nbs_predictions)):\n",
    "    if (nbs_predictions[i] == 0):\n",
    "    # model predicts negative\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 1):\n",
    "        # but training data says should have been positive; thus, false negative\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">WARNING: Don't look at test set performance too much!</span>\n",
    "\n",
    "---\n",
    "\n",
    "The following cells show performance on your test set. Do not look at this too often! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 1486, 'TN': 15056, 'FP': 13585, 'FN': 1788, 'Accuracy': 0.518314272285759, 'Precision': 0.09859996018844137, 'Recall': 0.4538790470372633, 'desc': 'ols_test'}\n",
      "False Positive Rate:\n",
      "0.4743200307251842\n",
      "True Positive Rate:\n",
      "0.4538790470372633\n"
     ]
    }
   ],
   "source": [
    "ols_performance_test = BinaryClassificationPerformance(ols.predict(X_test), y_test, 'ols_test')\n",
    "ols_performance_test.compute_measures()\n",
    "print(ols_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(ols_performance_test.performance_measures['FP'] / ols_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(ols_performance_test.performance_measures['TP'] / ols_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2486, 'TN': 27403, 'FP': 1238, 'FN': 788, 'Accuracy': 0.9365188782704058, 'Precision': 0.667561761546724, 'Recall': 0.7593158216249236, 'desc': 'svm_test'}\n",
      "False Positive Rate:\n",
      "0.043224747739254915\n",
      "True Positive Rate:\n",
      "0.7593158216249236\n"
     ]
    }
   ],
   "source": [
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(svm_performance_test.performance_measures['FP'] / svm_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(svm_performance_test.performance_measures['TP'] / svm_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgs_performance_test = BinaryClassificationPerformance(lgs.predict(X_test), y_test, 'lgs_test')\n",
    "lgs_performance_test.compute_measures()\n",
    "print(lgs_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(lgs_performance_test.performance_measures['FP'] / lgs_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(lgs_performance_test.performance_measures['TP'] / lgs_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2355, 'TN': 27952, 'FP': 689, 'FN': 919, 'Accuracy': 0.9496161679461068, 'Precision': 0.7736530880420499, 'Recall': 0.7193036041539401, 'desc': 'lgr_test'}\n",
      "False Positive Rate:\n",
      "0.024056422610942357\n",
      "True Positive Rate:\n",
      "0.7193036041539401\n"
     ]
    }
   ],
   "source": [
    "lgr_performance_test = BinaryClassificationPerformance(lgr.predict(X2_test), y2_test, 'lgr_test')\n",
    "lgr_performance_test.compute_measures()\n",
    "print(lgr_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(lgr_performance_test.performance_measures['FP'] / lgr_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(lgr_performance_test.performance_measures['TP'] / lgr_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2704, 'TN': 25715, 'FP': 2926, 'FN': 570, 'Accuracy': 0.8904590318032273, 'Precision': 0.4802841918294849, 'Recall': 0.8259010384850336, 'desc': 'nbs_test'}\n",
      "False Positive Rate:\n",
      "0.10216123738696274\n",
      "True Positive Rate:\n",
      "0.8259010384850336\n"
     ]
    }
   ],
   "source": [
    "nbs_performance_test = BinaryClassificationPerformance(nbs.predict(X2_test), y2_test, 'nbs_test')\n",
    "nbs_performance_test.compute_measures()\n",
    "print(nbs_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(nbs_performance_test.performance_measures['FP'] / nbs_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(nbs_performance_test.performance_measures['TP'] / nbs_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 3145, 'TN': 19410, 'FP': 9231, 'FN': 129, 'Accuracy': 0.7067209775967414, 'Precision': 0.2541208791208791, 'Recall': 0.9605986560781918, 'desc': 'cnb_test'}\n",
      "True Positive Rate:\n",
      "96.05986560781918\n",
      "False Positive Rate:\n",
      "32.230019901539755\n",
      "False Negative Rate:\n",
      "3.9401343921808185\n"
     ]
    }
   ],
   "source": [
    "# Complement NB\n",
    "cnb_performance_test = BinaryClassificationPerformance(cnb.predict(X2_test), y2_test, 'cnb_test')\n",
    "cnb_performance_test.compute_measures()\n",
    "print(cnb_performance_test.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(cnb_performance_test.performance_measures['TP'] / cnb_performance_test.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(cnb_performance_test.performance_measures['FP'] / cnb_performance_test.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(cnb_performance_test.performance_measures['FN'] / cnb_performance_test.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 1963, 'TN': 28170, 'FP': 471, 'FN': 1311, 'Accuracy': 0.9441641861193796, 'Precision': 0.8064913722267871, 'Recall': 0.5995723885155773, 'desc': 'prc_test'}\n",
      "False Positive Rate:\n",
      "0.016444956530847387\n",
      "True Positive Rate:\n",
      "0.5995723885155773\n"
     ]
    }
   ],
   "source": [
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(prc_performance_test.performance_measures['FP'] / prc_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(prc_performance_test.performance_measures['TP'] / prc_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators = [('nbs', nbs), ('cnb', cnb), ('rdg', rdg)]\n",
    "esb3 = VotingClassifier(estimators, voting='hard')\n",
    "esb3.fit(X2_train, y2_train)\n",
    "\n",
    "esb3_performance_train = BinaryClassificationPerformance(esb3.predict(X2_train), y2_train, 'esb3_train')\n",
    "esb3_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2901, 'TN': 25104, 'FP': 3537, 'FN': 373, 'Accuracy': 0.8774870750430832, 'Precision': 0.4506057781919851, 'Recall': 0.8860720830788027, 'desc': 'esb3_test'}\n",
      "True Positive Rate:\n",
      "88.60720830788027\n",
      "False Positive Rate:\n",
      "12.349429140043993\n"
     ]
    }
   ],
   "source": [
    "esb3_performance_test = BinaryClassificationPerformance(esb3.predict(X2_test), y2_test, 'esb3_test')\n",
    "esb3_performance_test.compute_measures()\n",
    "print(esb3_performance_test.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(esb3_performance_test.performance_measures['TP'] / esb3_performance_test.performance_measures['Pos'] *100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(esb3_performance_test.performance_measures['FP'] / esb3_performance_test.performance_measures['Neg'] *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2910, 'TN': 25963, 'FP': 2678, 'FN': 364, 'Accuracy': 0.904684317718941, 'Precision': 0.5207587687902648, 'Recall': 0.8888210140500916, 'desc': 'rdg_test'}\n",
      "True Positive Rate:\n",
      "88.88210140500917\n",
      "False Positive Rate:\n",
      "9.350232184630425\n",
      "False Negative Rate:\n",
      "11.117898594990837\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test = BinaryClassificationPerformance(rdg.predict(X_test), y_test, 'rdg_test')\n",
    "rdg_performance_test.compute_measures()\n",
    "print(rdg_performance_test.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test.performance_measures['TP'] / rdg_performance_test.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test.performance_measures['FP'] / rdg_performance_test.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test.performance_measures['FN'] / rdg_performance_test.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:\n",
      "97.00671960904093\n",
      "False Positive Rate:\n",
      "22.16053908732237\n",
      "False Negative Rate:\n",
      "2.9932803909590717\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_5 = BinaryClassificationPerformance(rdg_5.predict(X_test), y_test, 'rdg_test_5')\n",
    "rdg_performance_test_5.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_5.performance_measures['TP'] / rdg_performance_test_5.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_5.performance_measures['FP'] / rdg_performance_test_5.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_5.performance_measures['FN'] / rdg_performance_test_5.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test_7_5 = BinaryClassificationPerformance(rdg_7_5.predict(X_test), y_test, 'rdg_test_7_5')\n",
    "rdg_performance_test_7_5.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_7_5.performance_measures['TP'] / rdg_performance_test_7_5.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_7_5.performance_measures['FP'] / rdg_performance_test_7_5.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_7_5.performance_measures['FN'] / rdg_performance_test_7_5.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:\n",
      "95.29627367135004\n",
      "False Positive Rate:\n",
      "15.802520861701755\n",
      "False Negative Rate:\n",
      "4.703726328649969\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_10 = BinaryClassificationPerformance(rdg_10.predict(X_test), y_test, 'rdg_test_10')\n",
    "rdg_performance_test_10.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_10.performance_measures['TP'] / rdg_performance_test_10.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_10.performance_measures['FP'] / rdg_performance_test_10.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_10.performance_measures['FN'] / rdg_performance_test_10.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:\n",
      "92.79169211973122\n",
      "False Positive Rate:\n",
      "12.719527949443107\n",
      "False Negative Rate:\n",
      "7.2083078802687846\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_15 = BinaryClassificationPerformance(rdg_15.predict(X_test), y_test, 'rdg_test_15')\n",
    "rdg_performance_test_15.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_15.performance_measures['TP'] / rdg_performance_test_15.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_15.performance_measures['FP'] / rdg_performance_test_15.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_15.performance_measures['FN'] / rdg_performance_test_15.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:\n",
      "90.92852779474649\n",
      "False Positive Rate:\n",
      "10.704933486959254\n",
      "False Negative Rate:\n",
      "9.071472205253512\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_20 = BinaryClassificationPerformance(rdg_20.predict(X_test), y_test, 'rdg_test_20')\n",
    "rdg_performance_test_20.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_20.performance_measures['TP'] / rdg_performance_test_20.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_20.performance_measures['FP'] / rdg_performance_test_20.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_20.performance_measures['FN'] / rdg_performance_test_20.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2910, 'TN': 25961, 'FP': 2680, 'FN': 364, 'Accuracy': 0.9046216512611625, 'Precision': 0.5205724508050089, 'Recall': 0.8888210140500916, 'desc': 'rdg_test_25'}\n",
      "True Positive Rate:\n",
      "88.88210140500917\n",
      "False Positive Rate:\n",
      "9.357215181034181\n",
      "False Negative Rate:\n",
      "11.117898594990837\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_25 = BinaryClassificationPerformance(rdg_25.predict(X_test), y_test, 'rdg_test_25')\n",
    "rdg_performance_test_25.compute_measures()\n",
    "print(rdg_performance_test_25.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_25.performance_measures['TP'] / rdg_performance_test_25.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_25.performance_measures['FP'] / rdg_performance_test_25.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_25.performance_measures['FN'] / rdg_performance_test_25.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2843, 'TN': 26279, 'FP': 2362, 'FN': 431, 'Accuracy': 0.912486291712361, 'Precision': 0.5462055715658021, 'Recall': 0.8683567501527184, 'desc': 'rdg_test_30'}\n",
      "True Positive Rate:\n",
      "86.83567501527185\n",
      "False Positive Rate:\n",
      "8.246918752836843\n",
      "False Negative Rate:\n",
      "13.164324984728163\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_30 = BinaryClassificationPerformance(rdg_30.predict(X_test), y_test, 'rdg_test_30')\n",
    "rdg_performance_test_30.compute_measures()\n",
    "print(rdg_performance_test_30.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_30.performance_measures['TP'] / rdg_performance_test_30.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_30.performance_measures['FP'] / rdg_performance_test_30.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_30.performance_measures['FN'] / rdg_performance_test_30.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test_35 = BinaryClassificationPerformance(rdg_35.predict(X_test), y_test, 'rdg_test_35')\n",
    "rdg_performance_test_35.compute_measures()\n",
    "print(rdg_performance_test_35.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_35.performance_measures['TP'] / rdg_performance_test_35.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_35.performance_measures['FP'] / rdg_performance_test_35.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_35.performance_measures['FN'] / rdg_performance_test_35.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test_40 = BinaryClassificationPerformance(rdg_40.predict(X_test), y_test, 'rdg_test_40')\n",
    "rdg_performance_test_40.compute_measures()\n",
    "print(rdg_performance_test_40.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_40.performance_measures['TP'] / rdg_performance_test_40.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_40.performance_measures['FP'] / rdg_performance_test_40.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_40.performance_measures['FN'] / rdg_performance_test_40.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf_performance_test = BinaryClassificationPerformance(rdf.predict(X_test), y_test, 'rdf_test')\n",
    "# rdf_performance_test.compute_measures()\n",
    "# print(rdf_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [rdg_performance_test, nbs_performance_test, cnb_performance_test, lgr_performance_test, esb3_performance_test]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "    \n",
    "# fits = [rdg_performance_train, rdg_performance_train_1, rdg_performance_train_2, rdg_performance_train_5, rdg_performance_train_7, rdg_performance_train_9]\n",
    "\n",
    "# for fit in fits:\n",
    "#     plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'rx')\n",
    "#     plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)    \n",
    "\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.grid(b=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdg plot\n",
    "fits = [rdg_performance_test_5, rdg_performance_test_10, rdg_performance_test_15, rdg_performance_test_20, rdg_performance_test_25, rdg_performance_test_30]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "    \n",
    "# fits = [rdg_performance_train, rdg_performance_train_1, rdg_performance_train_2, rdg_performance_train_5, rdg_performance_train_7, rdg_performance_train_9]\n",
    "\n",
    "# for fit in fits:\n",
    "#     plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'rx')\n",
    "#     plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)    \n",
    "\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.grid(b=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">SUBMISSION</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 5 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 131072)\n",
      "Shape of HashingVectorizer char n_gram X:\n",
      "(153164, 16384)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   consCapsword_ratio  consCaps_ratio  consCaps_count  spaceswords_ratio  \\\n",
      "0            0.000000        0.000000               0           0.986111   \n",
      "1            0.076923        0.020000               1           0.923077   \n",
      "2            0.000000        0.000000               0           0.937500   \n",
      "3            0.000000        0.000000               0           0.973684   \n",
      "4            0.000000        0.000000               0           0.857143   \n",
      "5            0.000000        0.000000               0           0.937500   \n",
      "6            0.000000        0.000000               0           0.967742   \n",
      "7            0.000000        0.000000               0           0.833333   \n",
      "8            0.073394        0.014388               8           0.990826   \n",
      "9            0.000000        0.000000               0           0.975610   \n",
      "\n",
      "   spaces_ratio  spaces_count  char_count  Caps_count  Caps_ratio  word_count  \\\n",
      "0      0.193460            71         367           4    0.000003          72   \n",
      "1      0.240000            12          50           7    0.004096          13   \n",
      "2      0.277778            15          54           4    0.000794          16   \n",
      "3      0.180488            37         205           4    0.000015          38   \n",
      "4      0.146341             6          41           1    0.000116           7   \n",
      "5      0.156250            15          96           2    0.000031          16   \n",
      "6      0.170455            30         176           5    0.000040          31   \n",
      "7      0.156250             5          32           1    0.000244           6   \n",
      "8      0.194245           108         556          41    0.000431         109   \n",
      "9      0.178571            40         224           7    0.000046          41   \n",
      "\n",
      "   char_ratio  punc_count_p  punc_count_exc  punc_count_q  punc_count  \\\n",
      "0    5.097222            10               0             0          10   \n",
      "1    3.846154             1               0             0           1   \n",
      "2    3.375000             0               0             0           0   \n",
      "3    5.394737             3               0             0           3   \n",
      "4    5.857143             1               0             0           1   \n",
      "5    6.000000             2               0             0           2   \n",
      "6    5.677419             4               0             0           4   \n",
      "7    5.333333             1               0             0           1   \n",
      "8    5.100917             9               0             0           9   \n",
      "9    5.463415             0               0             0           0   \n",
      "\n",
      "   punc_ratio  Capsword_ratio  \n",
      "0    0.138889        0.194444  \n",
      "1    0.076923        0.615385  \n",
      "2    0.000000        0.250000  \n",
      "3    0.078947        0.184211  \n",
      "4    0.142857        0.285714  \n",
      "5    0.125000        0.250000  \n",
      "6    0.129032        0.290323  \n",
      "7    0.166667        0.333333  \n",
      "8    0.082569        0.458716  \n",
      "9    0.000000        0.170732  \n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 147473)\n",
      "(153164, 147473)\n",
      "Shape of X_test for submission:\n",
      "(153164, 147473)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data, X_test_submission = process_raw_data(fn='/Users/Charles/Desktop/ML/A1/toxiccomments_test.csv', my_random_seed=36, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 5 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 16384)\n",
      "Shape of HashingVectorizer char n_gram X:\n",
      "(153164, 16384)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   consCaps_count  consCaps_ratio  consCapsword_ratio  punc_q_ratio  \\\n",
      "0               0        0.000000            0.000000      0.009009   \n",
      "1               1        0.020000            0.076923      0.047619   \n",
      "2               0        0.000000            0.000000      0.090909   \n",
      "3               0        0.000000            0.000000      0.024390   \n",
      "4               0        0.000000            0.000000      0.090909   \n",
      "5               0        0.000000            0.000000      0.047619   \n",
      "6               0        0.000000            0.000000      0.019608   \n",
      "7               0        0.000000            0.000000      0.090909   \n",
      "8               8        0.014388            0.073394      0.009901   \n",
      "9               0        0.000000            0.000000      0.019608   \n",
      "\n",
      "   punc_exc_ratio  punc_count_s  punc_count_a  punc_count_c  \\\n",
      "0        0.009009             0             0             1   \n",
      "1        0.047619             0             0             1   \n",
      "2        0.090909             0             1             0   \n",
      "3        0.024390             0             0             1   \n",
      "4        0.090909             0             0             0   \n",
      "5        0.047619             0             0             0   \n",
      "6        0.019608             0             0             1   \n",
      "7        0.090909             0             0             0   \n",
      "8        0.009901             0             0             1   \n",
      "9        0.019608             0             0             5   \n",
      "\n",
      "   spaceswords_ratio  spaces_ratio  ...  Caps_count  Caps_ratio  word_count  \\\n",
      "0           0.986111      0.193460  ...           4    0.000003          72   \n",
      "1           0.923077      0.240000  ...           7    0.004096          13   \n",
      "2           0.937500      0.277778  ...           4    0.000794          16   \n",
      "3           0.973684      0.180488  ...           4    0.000015          38   \n",
      "4           0.857143      0.146341  ...           1    0.000116           7   \n",
      "5           0.937500      0.156250  ...           2    0.000031          16   \n",
      "6           0.967742      0.170455  ...           5    0.000040          31   \n",
      "7           0.833333      0.156250  ...           1    0.000244           6   \n",
      "8           0.990826      0.194245  ...          41    0.000431         109   \n",
      "9           0.975610      0.178571  ...           7    0.000046          41   \n",
      "\n",
      "   char_ratio  punc_count_p  punc_count_exc  punc_count_q  punc_count  \\\n",
      "0    5.097222            10               0             0          11   \n",
      "1    3.846154             1               0             0           2   \n",
      "2    3.375000             0               0             0           1   \n",
      "3    5.394737             3               0             0           4   \n",
      "4    5.857143             1               0             0           1   \n",
      "5    6.000000             2               0             0           2   \n",
      "6    5.677419             4               0             0           5   \n",
      "7    5.333333             1               0             0           1   \n",
      "8    5.100917             9               0             0          10   \n",
      "9    5.463415             0               0             0           5   \n",
      "\n",
      "   punc_ratio  Capsword_ratio  \n",
      "0    0.152778        0.208333  \n",
      "1    0.153846        0.692308  \n",
      "2    0.062500        0.312500  \n",
      "3    0.105263        0.210526  \n",
      "4    0.142857        0.285714  \n",
      "5    0.125000        0.250000  \n",
      "6    0.161290        0.322581  \n",
      "7    0.166667        0.333333  \n",
      "8    0.091743        0.467890  \n",
      "9    0.121951        0.292683  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 32790)\n",
      "(153164, 32790)\n",
      "Shape of X_test for submission:\n",
      "(153164, 32790)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data2, X2_test_submission = process_raw_data2(fn='/Users/Charles/Desktop/ML/A1/toxiccomments_test.csv', my_random_seed=36, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a <span style=\"color:red\">*single*</span> model for your submission. In this code, I am choosing the Ordinary Least Squares model fit, which is in the `ols` object. But you should choose the model that is performing the best for you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the id from the raw data\n",
    "my_submission2 = pd.DataFrame(raw_data2[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission2[\"esb\"] = esb3.predict(X2_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "# print(my_submission['prediction'].mean())\n",
    "\n",
    "my_submission2[\"nbs\"] = nbs.predict(X2_test_submission)\n",
    "\n",
    "my_submission2[\"cnb\"] = cnb.predict(X2_test_submission)\n",
    "\n",
    "my_submission2[\"lgr\"] = lgr.predict(X2_test_submission)\n",
    "\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "\n",
    "my_submission[\"rdg\"] = rdg.predict(X_test_submission)\n",
    "\n",
    "# print(my_submission[\"rdg\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 2)\n",
      "(153164, 5)\n",
      "                 id prediction_ens\n",
      "0  00001cee341fdb12           True\n",
      "1  0000247867823ef7          False\n",
      "2  00013b17ad220c46          False\n",
      "3  00017563c3f7919a          False\n",
      "4  00017695ad8997eb          False\n",
      "5  0001ea8717f6de06          False\n",
      "6  00024115d4cbde0f          False\n",
      "7  000247e83dcc1211           True\n",
      "8  00025358d4737918          False\n",
      "9  00026d1092fe71cc          False\n"
     ]
    }
   ],
   "source": [
    "print(my_submission.shape)\n",
    "print(my_submission2.shape)\n",
    "m1 = pd.concat([my_submission2, my_submission[\"rdg\"]], axis=1)\n",
    "# print(m1.head(50))\n",
    "# [\"prediction_esb\", \"prediction_nbs\", \"prediction_cnb\", \"prediction_lgr\", \"prediction_rdg\"]\n",
    "m1[\"Ensemble\"] = m1[\"esb\"]*0.03 + m1[\"rdg\"]*1.02 + m1[\"nbs\"]*0.99 + m1[\"cnb\"]*0.98 + m1[\"lgr\"]*0.98\n",
    "m1[\"ens_int\"] = (m1[\"Ensemble\"]>2).astype(int)\n",
    "# print(Ensemble.head(50))\n",
    "# print(m1[\"ens_int\"].head(50))\n",
    "m1[\"prediction_ens\"] = m1[\"ens_int\"].replace({0: \"False\", 1: \"True\"})\n",
    "# print(ens.head(50))\n",
    "my_final = pd.concat([m1[\"id\"], m1[\"prediction_ens\"]], axis=1)\n",
    "print(my_final.head(10))\n",
    "# my_final = my_final.rename(columns={0: \"prediction_ens\"}, inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction_ens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id prediction_ens\n",
       "0  00001cee341fdb12           True\n",
       "1  0000247867823ef7          False\n",
       "2  00013b17ad220c46          False\n",
       "3  00017563c3f7919a          False\n",
       "4  00017695ad8997eb          False\n",
       "5  0001ea8717f6de06          False\n",
       "6  00024115d4cbde0f          False\n",
       "7  000247e83dcc1211           True\n",
       "8  00025358d4737918          False\n",
       "9  00026d1092fe71cc          False"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final.head(10)\n",
    "# my_submission.to_csv('/Users/Charles/Desktop/ML/A1/toxiccomments_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_final.to_csv('/Users/Charles/Desktop/ML/A1/toxiccomments_5th_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">SUBMISSION</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29366561332950303\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = rdg_30.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Caps_count</th>\n",
       "      <th>Caps_ratio</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_ratio</th>\n",
       "      <th>punc_count_p</th>\n",
       "      <th>punc_count_exc</th>\n",
       "      <th>punc_count_q</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>punc_ratio</th>\n",
       "      <th>Capsword_ratio</th>\n",
       "      <th>spaces_count</th>\n",
       "      <th>spaces_ratio</th>\n",
       "      <th>spaceswords_ratio</th>\n",
       "      <th>consCaps_count</th>\n",
       "      <th>consCaps_ratio</th>\n",
       "      <th>consCapsword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>367</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>72</td>\n",
       "      <td>5.097222</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>71</td>\n",
       "      <td>0.193460</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>13</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>12</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>16</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>205</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>38</td>\n",
       "      <td>5.394737</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>37</td>\n",
       "      <td>0.180488</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>7</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "   char_count  Caps_count  Caps_ratio  word_count  char_ratio  punc_count_p  \\\n",
       "0         367           4    0.000003          72    5.097222            10   \n",
       "1          50           7    0.004096          13    3.846154             1   \n",
       "2          54           4    0.000794          16    3.375000             0   \n",
       "3         205           4    0.000015          38    5.394737             3   \n",
       "4          41           1    0.000116           7    5.857143             1   \n",
       "\n",
       "   punc_count_exc  punc_count_q  punc_count  punc_ratio  Capsword_ratio  \\\n",
       "0               0             0          10    0.138889        0.194444   \n",
       "1               0             0           1    0.076923        0.615385   \n",
       "2               0             0           0    0.000000        0.250000   \n",
       "3               0             0           3    0.078947        0.184211   \n",
       "4               0             0           1    0.142857        0.285714   \n",
       "\n",
       "   spaces_count  spaces_ratio  spaceswords_ratio  consCaps_count  \\\n",
       "0            71      0.193460           0.986111               0   \n",
       "1            12      0.240000           0.923077               1   \n",
       "2            15      0.277778           0.937500               0   \n",
       "3            37      0.180488           0.973684               0   \n",
       "4             6      0.146341           0.857143               0   \n",
       "\n",
       "   consCaps_ratio  consCapsword_ratio  \n",
       "0            0.00            0.000000  \n",
       "1            0.02            0.076923  \n",
       "2            0.00            0.000000  \n",
       "3            0.00            0.000000  \n",
       "4            0.00            0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  00001cee341fdb12        True\n",
       "1  0000247867823ef7       False\n",
       "2  00013b17ad220c46       False\n",
       "3  00017563c3f7919a       False\n",
       "4  00017695ad8997eb       False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv('/Users/Charles/Desktop/ML/A1/toxiccomments_4th_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Canvas: 1) the CSV file that was written in the previous cell and 2) the url to the repository (GitHub or other) that contains your code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
