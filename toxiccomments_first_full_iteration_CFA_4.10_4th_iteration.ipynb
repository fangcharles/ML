{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic comments\n",
    "\n",
    "This notebook takes you though a complete iteration of Machine Learning Assignment 1 - Toxic comments. The assignment details (including links to download the data) can be found [here](https://docs.google.com/document/d/1WGYw99e5q6j5V0Zrf2HveagU6URt_kVvdR8B9HYQ99E/edit?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!!! Make sure you are using `BinaryClassificationPerformance` v1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for feature building and extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 5 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False, ngram_range=(1,2), stop_words='english')       \n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    # submission condition is test: what's the diff between test and not test here?  \n",
    "    # 'fitted_transformations.append' vs. '.transform'.  Why in the test condition does transform the data\n",
    "    # \"fit\" computes the mean and std to be used for later scaling. (just a computation) \n",
    "    # \"transform\" uses a previously computed mean and std to autoscale the data\n",
    "        \n",
    "    if (not test):\n",
    "        chv = HashingVectorizer(n_features=2 ** 14, alternate_sign=False, analyzer='char_wb', ngram_range=(2,4))\n",
    "        X_chv = chv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations.append(chv)\n",
    "        print(\"Shape of HashingVectorizer char n_gram X:\")\n",
    "        print(X_chv.shape)\n",
    "    else:\n",
    "        X_chv = fitted_transformations[1].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer char n_gram X:\")\n",
    "        print(X_chv.shape)\n",
    "    \n",
    "#     X_cv = hstack([X_hv, X_chv])\n",
    "#     print(\"Shape of Vectorizer combined X:\")\n",
    "#     print(X_cv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "#     if (not test):\n",
    "#         transformer = TfidfTransformer()\n",
    "#         X_tfidf = transformer.fit_transform(X_cv)\n",
    "#         fitted_transformations.append(transformer)\n",
    "#     else:\n",
    "#         X_tfidf = fitted_transformations[1].transform(X_cv)\n",
    "    \n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[2].transform(X_hv)\n",
    "\n",
    "    #    \n",
    "    if (not test):\n",
    "        transformer_chv = TfidfTransformer()\n",
    "        X_tfidf_chv = transformer_chv.fit_transform(X_chv)\n",
    "        fitted_transformations.append(transformer_chv)\n",
    "    else:\n",
    "        X_tfidf_chv = fitted_transformations[3].transform(X_chv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "\n",
    "    # what does the form toxic_data['comment_text'] mean?\n",
    "    toxic_data['char_count'] = toxic_data['comment_text'].str.len()\n",
    "    toxic_data['Caps_count'] = toxic_data['comment_text'].str.count(r'[A-Z]')\n",
    "    toxic_data['Caps_ratio'] = pow((toxic_data['Caps_count']+1)/toxic_data['char_count'], 3)\n",
    "    \n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['char_ratio'] = toxic_data['char_count']/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['punc_count_p'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "    toxic_data['punc_count_exc'] = toxic_data['comment_text'].str.count(\"\\!\")\n",
    "    toxic_data['punc_count_q'] = toxic_data['comment_text'].str.count(\"\\?\")\n",
    "    \n",
    "    toxic_data['punc_count'] = toxic_data['punc_count_p'] + toxic_data['punc_count_exc'] + toxic_data['punc_count_q']\n",
    "    toxic_data['punc_ratio'] = toxic_data['punc_count']/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['Capsword_ratio'] = (toxic_data['Caps_count'] + toxic_data['punc_count'])/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['spaces_count'] = toxic_data['comment_text'].str.count(\" \")\n",
    "    toxic_data['spaces_ratio'] = toxic_data['spaces_count']/toxic_data['char_count']\n",
    "    toxic_data['spaceswords_ratio'] = toxic_data['spaces_count']/toxic_data['word_count']\n",
    "    \n",
    "    # count the number of consecutive caps letters\n",
    "    toxic_data['consCaps_count'] = toxic_data['comment_text'].str.count(r'[A-Z]{3}')\n",
    "    toxic_data['consCaps_ratio'] = toxic_data['consCaps_count']/toxic_data['char_count']\n",
    "    toxic_data['consCapsword_ratio'] = toxic_data['consCaps_count']/toxic_data['word_count']\n",
    "    \n",
    "    # current count: 17 quant features\n",
    "    X_quant_features = toxic_data[[\"consCapsword_ratio\", \"consCaps_ratio\", \"consCaps_count\", \"spaceswords_ratio\", \"spaces_ratio\", \"spaces_count\", \"char_count\", \"Caps_count\", \"Caps_ratio\", \"word_count\", \"char_ratio\", \"punc_count_p\", \"punc_count_exc\", \"punc_count_q\", \"punc_count\", \"punc_ratio\", \"Capsword_ratio\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "#     X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_combined = hstack([X_tfidf, X_tfidf_chv, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X = fitted_transformations[4].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "\n",
    "#     # polynomialregression\n",
    "#     if (not test):\n",
    "#         poly = PolynomialFeatures(degree=2, interaction_only=True, order='F')\n",
    "#         X = poly.fit_transform(X_matrix)\n",
    "#         fitted_transformations.append(poly)\n",
    "#         print(X.shape)\n",
    "#         y = toxic_data['any_toxic']\n",
    "#     else:\n",
    "#         X = fitted_transformations[4].transform(X_matrix)\n",
    "#         print(X.shape)\n",
    "    \n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2\n",
    "def process_raw_data2(fn, my_random_seed, test=False):\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 5 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    if (not test): # fit_transform()\n",
    "        hv2 = HashingVectorizer(n_features=2 ** 14, alternate_sign=False, \n",
    "                               ngram_range=(1,2), token_pattern=r'\\b\\w+\\b', \n",
    "                               stop_words='english')       \n",
    "        X_hv2 = hv2.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations2.append(hv2)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv2.shape)\n",
    "    else: # transform() \n",
    "        X_hv2 = fitted_transformations2[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv2.shape)\n",
    "        \n",
    "    if (not test):\n",
    "        chv2 = HashingVectorizer(n_features=2 ** 14, alternate_sign=False, \n",
    "                                analyzer='char_wb', ngram_range=(2,4))\n",
    "        X_chv2 = chv2.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations2.append(chv2)\n",
    "        print(\"Shape of HashingVectorizer char n_gram X:\")\n",
    "        print(X_chv2.shape)\n",
    "    else:\n",
    "        X_chv2 = fitted_transformations2[1].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer char n_gram X:\")\n",
    "        print(X_chv2.shape)\n",
    "    \n",
    "    if (not test):\n",
    "        transformer2 = TfidfTransformer()\n",
    "        X_tfidf2 = transformer2.fit_transform(X_hv2)\n",
    "        fitted_transformations2.append(transformer2)\n",
    "    else:\n",
    "        X_tfidf2 = fitted_transformations2[2].transform(X_hv2)\n",
    "\n",
    "    # character n-grams   \n",
    "    if (not test):\n",
    "        transformer_chv2 = TfidfTransformer()\n",
    "        X_tfidf_chv2 = transformer_chv2.fit_transform(X_chv2)\n",
    "        fitted_transformations2.append(transformer_chv2)\n",
    "    else:\n",
    "        X_tfidf_chv2 = fitted_transformations2[3].transform(X_chv2)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    toxic_data['char_count'] = toxic_data['comment_text'].str.len()\n",
    "    toxic_data['Caps_count'] = toxic_data['comment_text'].str.count(r'[A-Z]')\n",
    "    toxic_data['Caps_ratio'] = pow((toxic_data['Caps_count']+1)/toxic_data['char_count'], 3)\n",
    "    \n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['char_ratio'] = toxic_data['char_count']/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['punc_count_p'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "    toxic_data['punc_count_exc'] = toxic_data['comment_text'].str.count(\"\\!\")\n",
    "    toxic_data['punc_count_q'] = toxic_data['comment_text'].str.count(\"\\?\")\n",
    "    toxic_data['punc_count_c'] = toxic_data['comment_text'].str.count(\"\\,\")\n",
    "    toxic_data['punc_count_a'] = toxic_data['comment_text'].str.count(\"\\*\")\n",
    "    toxic_data['punc_count_s'] = toxic_data['comment_text'].str.count(\"\\;\")\n",
    "    \n",
    "    toxic_data['punc_count'] = toxic_data['punc_count_s'] + toxic_data['punc_count_a'] + toxic_data['punc_count_c'] + toxic_data['punc_count_p'] + toxic_data['punc_count_exc'] + toxic_data['punc_count_q']\n",
    "    toxic_data['punc_ratio'] = toxic_data['punc_count']/toxic_data['word_count']\n",
    "    toxic_data['punc_exc_ratio'] = (toxic_data['punc_count_exc']+0.1) / (toxic_data['punc_count']+0.1)\n",
    "    toxic_data['punc_q_ratio'] = (toxic_data['punc_count_q']+0.1) / (toxic_data['punc_count']+0.1)\n",
    "    \n",
    "    toxic_data['Capsword_ratio'] = (toxic_data['Caps_count'] + toxic_data['punc_count'])/toxic_data['word_count']\n",
    "    \n",
    "    toxic_data['spaces_count'] = toxic_data['comment_text'].str.count(\" \")\n",
    "    toxic_data['spaces_ratio'] = toxic_data['spaces_count']/toxic_data['char_count']\n",
    "    toxic_data['spaceswords_ratio'] = toxic_data['spaces_count']/toxic_data['word_count']\n",
    "    \n",
    "    # count the number of consecutive caps letters\n",
    "    toxic_data['consCaps_count'] = toxic_data['comment_text'].str.count(r'[A-Z]{3}')\n",
    "    toxic_data['consCaps_ratio'] = toxic_data['consCaps_count']/toxic_data['char_count']\n",
    "    toxic_data['consCapsword_ratio'] = toxic_data['consCaps_count']/toxic_data['word_count']\n",
    "    \n",
    "    # current count: 22 quant features\n",
    "    X_quant_features = toxic_data[[\"consCaps_count\", \"consCaps_ratio\", \"consCapsword_ratio\", \"punc_q_ratio\", \"punc_exc_ratio\", \"punc_count_s\", \"punc_count_a\", \"punc_count_c\", \"spaceswords_ratio\", \"spaces_ratio\", \"spaces_count\", \"char_count\", \"Caps_count\", \"Caps_ratio\", \"word_count\", \"char_ratio\", \"punc_count_p\", \"punc_count_exc\", \"punc_count_q\", \"punc_count\", \"punc_ratio\", \"Capsword_ratio\"]]\n",
    "    # for specific quant_feat\n",
    "#     X_quant_features = toxic_data[[\"char_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "        \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    # hstack wo char n-grams\n",
    "#     X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_combined2 = hstack([X_tfidf2, X_tfidf_chv2, X_quant_features_csr])\n",
    "    X_matrix2 = csr_matrix(X_combined2) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix2.shape)\n",
    "     \n",
    "        \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc2 = StandardScaler(with_mean=False)\n",
    "        X2 = sc2.fit_transform(X_matrix2)\n",
    "        fitted_transformations2.append(sc2)\n",
    "        print(X2.shape)\n",
    "        y2 = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X2 = fitted_transformations2[4].transform(X_matrix2)\n",
    "        print(X2.shape)\n",
    "\n",
    "\n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X2_submission_test = X2\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X2_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X2_submission_test)\n",
    "    else: \n",
    "        X2_train, X2_test, y2_train, y2_test, X2_raw_train, X2_raw_test = train_test_split(X2, y2, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X2_train.shape)\n",
    "        print(X2_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y2_train.shape)\n",
    "        print(y2_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X2_raw_train.shape)\n",
    "        print(X2_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X2_train, X2_test, y2_train, y2_test, X2_raw_train, X2_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test sets from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 5 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "Shape of HashingVectorizer char n_gram X:\n",
      "(159571, 16384)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   consCapsword_ratio  consCaps_ratio  consCaps_count  spaceswords_ratio  \\\n",
      "0            0.023810        0.003788               1           0.976190   \n",
      "1            0.055556        0.008929               1           0.944444   \n",
      "2            0.000000        0.000000               0           0.976190   \n",
      "3            0.000000        0.000000               0           0.991071   \n",
      "4            0.000000        0.000000               0           0.923077   \n",
      "5            0.000000        0.000000               0           0.916667   \n",
      "6            1.250000        0.227273              10           0.875000   \n",
      "7            0.000000        0.000000               0           0.952381   \n",
      "8            0.000000        0.000000               0           0.987952   \n",
      "9            0.000000        0.000000               0           0.916667   \n",
      "\n",
      "   spaces_ratio  spaces_count  char_count  Caps_count  Caps_ratio  word_count  \\\n",
      "0      0.155303            41         264          17    0.000317          42   \n",
      "1      0.151786            17         112           8    0.000519          18   \n",
      "2      0.175966            41         233           4    0.000010          42   \n",
      "3      0.178457           111         622          11    0.000007         112   \n",
      "4      0.179104            12          67           2    0.000090          13   \n",
      "5      0.169231            11          65           1    0.000029          12   \n",
      "6      0.159091             7          44          37    0.644159           8   \n",
      "7      0.173913            20         115           4    0.000082          21   \n",
      "8      0.173729            82         472           7    0.000005          83   \n",
      "9      0.157143            11          70           2    0.000079          12   \n",
      "\n",
      "   char_ratio  punc_count_p  punc_count_exc  punc_count_q  punc_count  \\\n",
      "0    6.285714             5               0             1           6   \n",
      "1    6.222222             2               1             0           3   \n",
      "2    5.547619             3               0             0           3   \n",
      "3    5.553571             3               0             0           3   \n",
      "4    5.153846             1               0             1           2   \n",
      "5    5.416667             1               0             0           1   \n",
      "6    5.500000             0               0             0           0   \n",
      "7    5.476190             2               0             0           2   \n",
      "8    5.686747             7               0             1           8   \n",
      "9    5.833333             0               0             0           0   \n",
      "\n",
      "   punc_ratio  Capsword_ratio  \n",
      "0    0.142857        0.547619  \n",
      "1    0.166667        0.611111  \n",
      "2    0.071429        0.166667  \n",
      "3    0.026786        0.125000  \n",
      "4    0.153846        0.307692  \n",
      "5    0.083333        0.166667  \n",
      "6    0.000000        4.625000  \n",
      "7    0.095238        0.285714  \n",
      "8    0.096386        0.180723  \n",
      "9    0.000000        0.166667  \n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 147473)\n",
      "(159571, 147473)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 147473)\n",
      "(31915, 147473)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 26)\n",
      "(31915, 26)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "5\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='/Users/Charles/Desktop/ML/A1/toxiccomments_train.csv', my_random_seed=36)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 5 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 16384)\n",
      "Shape of HashingVectorizer char n_gram X:\n",
      "(159571, 16384)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   consCaps_count  consCaps_ratio  consCapsword_ratio  punc_q_ratio  \\\n",
      "0               1        0.003788            0.023810      0.154930   \n",
      "1               1        0.008929            0.055556      0.019608   \n",
      "2               0        0.000000            0.000000      0.024390   \n",
      "3               0        0.000000            0.000000      0.019608   \n",
      "4               0        0.000000            0.000000      0.268293   \n",
      "5               0        0.000000            0.000000      0.047619   \n",
      "6              10        0.227273            1.250000      1.000000   \n",
      "7               0        0.000000            0.000000      0.032258   \n",
      "8               0        0.000000            0.000000      0.108911   \n",
      "9               0        0.000000            0.000000      1.000000   \n",
      "\n",
      "   punc_exc_ratio  punc_count_s  punc_count_a  punc_count_c  \\\n",
      "0        0.014085             0             0             1   \n",
      "1        0.215686             0             0             2   \n",
      "2        0.024390             0             0             1   \n",
      "3        0.019608             0             0             2   \n",
      "4        0.024390             0             0             2   \n",
      "5        0.047619             0             0             1   \n",
      "6        1.000000             0             0             0   \n",
      "7        0.032258             0             0             1   \n",
      "8        0.009901             0             0             2   \n",
      "9        1.000000             0             0             0   \n",
      "\n",
      "   spaceswords_ratio  spaces_ratio  ...  Caps_count  Caps_ratio  word_count  \\\n",
      "0           0.976190      0.155303  ...          17    0.000317          42   \n",
      "1           0.944444      0.151786  ...           8    0.000519          18   \n",
      "2           0.976190      0.175966  ...           4    0.000010          42   \n",
      "3           0.991071      0.178457  ...          11    0.000007         112   \n",
      "4           0.923077      0.179104  ...           2    0.000090          13   \n",
      "5           0.916667      0.169231  ...           1    0.000029          12   \n",
      "6           0.875000      0.159091  ...          37    0.644159           8   \n",
      "7           0.952381      0.173913  ...           4    0.000082          21   \n",
      "8           0.987952      0.173729  ...           7    0.000005          83   \n",
      "9           0.916667      0.157143  ...           2    0.000079          12   \n",
      "\n",
      "   char_ratio  punc_count_p  punc_count_exc  punc_count_q  punc_count  \\\n",
      "0    6.285714             5               0             1           7   \n",
      "1    6.222222             2               1             0           5   \n",
      "2    5.547619             3               0             0           4   \n",
      "3    5.553571             3               0             0           5   \n",
      "4    5.153846             1               0             1           4   \n",
      "5    5.416667             1               0             0           2   \n",
      "6    5.500000             0               0             0           0   \n",
      "7    5.476190             2               0             0           3   \n",
      "8    5.686747             7               0             1          10   \n",
      "9    5.833333             0               0             0           0   \n",
      "\n",
      "   punc_ratio  Capsword_ratio  \n",
      "0    0.166667        0.571429  \n",
      "1    0.277778        0.722222  \n",
      "2    0.095238        0.190476  \n",
      "3    0.044643        0.142857  \n",
      "4    0.307692        0.461538  \n",
      "5    0.166667        0.250000  \n",
      "6    0.000000        4.625000  \n",
      "7    0.142857        0.333333  \n",
      "8    0.120482        0.204819  \n",
      "9    0.000000        0.166667  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 32790)\n",
      "(159571, 32790)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 32790)\n",
      "(31915, 32790)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 31)\n",
      "(31915, 31)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "5\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# X2\n",
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations2 = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X2_train, X2_test, y2_train, y2_test, X2_raw_train, X2_raw_test = process_raw_data2(fn='/Users/Charles/Desktop/ML/A1/toxiccomments_train.csv', my_random_seed=36)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit (and tune) Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(ols_performance_train.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(ols_performance_train.performance_measures['FP'] / ols_performance_train.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(ols_performance_train.performance_measures['TP'] / ols_performance_train.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12162, 'TN': 113071, 'FP': 1634, 'FN': 789, 'Accuracy': 0.9810193018737858, 'Precision': 0.8815598724267903, 'Recall': 0.9390780634700023, 'desc': 'svm_train'}\n",
      "False Positive Rate:\n",
      "0.014245237783880389\n",
      "True Positive Rate:\n",
      "0.9390780634700023\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(svm_performance_train.performance_measures['FP'] / svm_performance_train.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(svm_performance_train.performance_measures['TP'] / svm_performance_train.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 9587, 'TN': 112736, 'FP': 1969, 'FN': 3364, 'Accuracy': 0.958223663595914, 'Precision': 0.8296123226029768, 'Recall': 0.740251718014053, 'desc': 'lgs_train'}\n",
      "False Positive Rate:\n",
      "0.017165773070049257\n",
      "True Positive Rate:\n",
      "0.740251718014053\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log')\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(lgs_performance_train.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(lgs_performance_train.performance_measures['FP'] / lgs_performance_train.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(lgs_performance_train.performance_measures['TP'] / lgs_performance_train.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12948, 'TN': 114702, 'FP': 3, 'FN': 3, 'Accuracy': 0.9999529986839631, 'Precision': 0.9997683576557794, 'Recall': 0.9997683576557794, 'desc': 'lgr_train'}\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# lgr\n",
    "from sklearn import linear_model\n",
    "lgr = linear_model.LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "lgr.fit(X2_train, y2_train)\n",
    "\n",
    "lgr_performance_train = BinaryClassificationPerformance(lgr.predict(X2_train), y2_train, 'lgr_train')\n",
    "lgr_performance_train.compute_measures()\n",
    "print(lgr_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB(alpha=0.01)\n",
    "nbs.fit(X2_train, y2_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X2_train), y2_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 886 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Complement Naive Bayes\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "cnb = ComplementNB(alpha=0.00001, norm=True)\n",
    "cnb.fit(X2_train, y2_train)\n",
    "\n",
    "cnb_performance_train = BinaryClassificationPerformance(cnb.predict(X2_train), y2_train, 'cnb_train')\n",
    "cnb_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 8107, 'TN': 113326, 'FP': 1379, 'FN': 4844, 'Accuracy': 0.9512518017171148, 'Precision': 0.8546278726544381, 'Recall': 0.6259748281985947, 'desc': 'prc_train'}\n",
      "False Positive Rate:\n",
      "0.012022143760080206\n",
      "True Positive Rate:\n",
      "0.6259748281985947\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X_train, y_train)\n",
    "\n",
    "prc_performance_train = BinaryClassificationPerformance(prc.predict(X_train), y_train, 'prc_train')\n",
    "prc_performance_train.compute_measures()\n",
    "print(prc_performance_train.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(prc_performance_train.performance_measures['FP'] / prc_performance_train.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(prc_performance_train.performance_measures['TP'] / prc_performance_train.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# multilayer perceptron\n",
    "# too much runtime\n",
    "from sklearn import neural_network\n",
    "mlp = neural_network.MLPClassifier(hidden_layer_sizes=(2, 4))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp_performance_train = BinaryClassificationPerformance(mlp.predict(X_train), y_train, 'mlp_train')\n",
    "mlp_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier(alpha=0, normalize=True, solver='sag')\n",
    "rdg.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train = BinaryClassificationPerformance(rdg.predict(X_train), y_train, 'rdg')\n",
    "rdg_performance_train.compute_measures()\n",
    "print(rdg_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12947, 'TN': 96292, 'FP': 18413, 'FN': 4, 'Accuracy': 0.855729460424892, 'Precision': 0.41285076530612247, 'Recall': 0.9996911435410393, 'desc': 'rdg_5'}\n",
      "Wall time: 48.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_5 = linear_model.RidgeClassifier(alpha=5, normalize=True, solver='sag')\n",
    "rdg_5.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_5 = BinaryClassificationPerformance(rdg_5.predict(X_train), y_train, 'rdg_5')\n",
    "rdg_performance_train_5.compute_measures()\n",
    "print(rdg_performance_train_5.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_7p5 = linear_model.RidgeClassifier(alpha=7.5, normalize=True, solver='sag')\n",
    "rdg_7p5.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_7p5 = BinaryClassificationPerformance(rdg_7p5.predict(X_train), y_train, 'rdg_7p5')\n",
    "rdg_performance_train_7p5.compute_measures()\n",
    "print(rdg_performance_train_7p5.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12918, 'TN': 100553, 'FP': 14152, 'FN': 33, 'Accuracy': 0.8888810553362161, 'Precision': 0.4772072404876247, 'Recall': 0.9974519342135743, 'desc': 'rdg_10'}\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_10 = linear_model.RidgeClassifier(alpha=10, normalize=True, solver='sag')\n",
    "rdg_10.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_10 = BinaryClassificationPerformance(rdg_10.predict(X_train), y_train, 'rdg_10')\n",
    "rdg_performance_train_10.compute_measures()\n",
    "print(rdg_performance_train_10.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12796, 'TN': 102976, 'FP': 11729, 'FN': 155, 'Accuracy': 0.9069060600363477, 'Precision': 0.5217533129459735, 'Recall': 0.9880318122152729, 'desc': 'rdg_15'}\n",
      "Wall time: 45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_15 = linear_model.RidgeClassifier(alpha=15, normalize=True, solver='sag')\n",
    "rdg_15.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_15 = BinaryClassificationPerformance(rdg_15.predict(X_train), y_train, 'rdg_15')\n",
    "rdg_performance_train_15.compute_measures()\n",
    "print(rdg_performance_train_15.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12653, 'TN': 104604, 'FP': 10101, 'FN': 298, 'Accuracy': 0.9185388857554678, 'Precision': 0.5560780522106004, 'Recall': 0.976990193807428, 'desc': 'rdg_20'}\n",
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_20 = linear_model.RidgeClassifier(alpha=20, normalize=True, solver='sag')\n",
    "rdg_20.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_20 = BinaryClassificationPerformance(rdg_20.predict(X_train), y_train, 'rdg_20')\n",
    "rdg_performance_train_20.compute_measures()\n",
    "print(rdg_performance_train_20.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12455, 'TN': 105852, 'FP': 8853, 'FN': 496, 'Accuracy': 0.9267641160619164, 'Precision': 0.5845222451661348, 'Recall': 0.9617017990888734, 'desc': 'rdg_25'}\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_25 = linear_model.RidgeClassifier(alpha=25, normalize=True, solver='sag')\n",
    "rdg_25.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_25 = BinaryClassificationPerformance(rdg_25.predict(X_train), y_train, 'rdg_25')\n",
    "rdg_performance_train_25.compute_measures()\n",
    "print(rdg_performance_train_25.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 12242, 'TN': 106781, 'FP': 7924, 'FN': 709, 'Accuracy': 0.9323729397756471, 'Precision': 0.6070613904591887, 'Recall': 0.9452551926492163, 'desc': 'rdg_30'}\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_30 = linear_model.RidgeClassifier(alpha=30, normalize=True, solver='sag')\n",
    "rdg_30.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_30 = BinaryClassificationPerformance(rdg_30.predict(X_train), y_train, 'rdg_30')\n",
    "rdg_performance_train_30.compute_measures()\n",
    "print(rdg_performance_train_30.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    943\u001b[0m                              compute_sample_weight(self.class_weight, y))\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sag'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_n_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 return_intercept=True, check_input=False)\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[1;31m# add the offset which was subtracted by _preprocess_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my_offset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36m_ridge_regression\u001b[1;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input)\u001b[0m\n\u001b[0;32m    487\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'squared'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 init, is_saga=solver == 'saga')\n\u001b[0m\u001b[0;32m    490\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_intercept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                 \u001b[0mcoef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    324\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                             verbose)\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_35 = linear_model.RidgeClassifier(alpha=35, normalize=True, solver='sag')\n",
    "rdg_35.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_35 = BinaryClassificationPerformance(rdg_35.predict(X_train), y_train, 'rdg_35')\n",
    "rdg_performance_train_35.compute_measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "rdg_40 = linear_model.RidgeClassifier(alpha=40, normalize=True, solver='sag')\n",
    "rdg_40.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train_40 = BinaryClassificationPerformance(rdg_40.predict(X_train), y_train, 'rdg_40')\n",
    "rdg_performance_train_40.compute_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12951, 'Neg': 114705, 'TP': 0, 'TN': 114705, 'FP': 0, 'FN': 12951, 'Accuracy': 0.8985476593344613, 'Precision': nan, 'Recall': 0.0, 'desc': 'rdf_train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charles\\Desktop\\ML\\A1\\my_measures.py:25: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  self.performance_measures['Precision'] = self.performance_measures['TP'] / (self.performance_measures['TP'] + self.performance_measures['FP'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# manipulate max_depth\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "rdf_performance_train = BinaryClassificationPerformance(rdf.predict(X_train), y_train, 'rdf_train')\n",
    "rdf_performance_train.compute_measures()\n",
    "print(rdf_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fits = [ols_performance_train, svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fits = [rdg_performance_train, rdg_performance_train_1, rdg_performance_train_2, rdg_performance_train_7, rdg_performance_train_9, rdg_performance_train_13, rdg_performance_train_19]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0.000415, 0.00043, 0.961, .963])\n",
    "plt.title('ROC plot Ridge Regression: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at reviews based on their classification\n",
    "\n",
    "Let's say we decide that Ordinary Least Squares (OLS) Regression is the best model for generalization. Let's take a look at some of the reviews and try to make a (subjective) determination of whether it's generalizing well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look at some false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_predictions = nbs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(nbs_predictions)):\n",
    "    if (nbs_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true positives\n",
    "\n",
    "print(\"Examples of true positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(nbs_predictions)):\n",
    "    if (ols_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 1):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "\n",
    "print(\"Examples of false negatives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(nbs_predictions)):\n",
    "    if (nbs_predictions[i] == 0):\n",
    "    # model predicts negative\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 1):\n",
    "        # but training data says should have been positive; thus, false negative\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">WARNING: Don't look at test set performance too much!</span>\n",
    "\n",
    "---\n",
    "\n",
    "The following cells show performance on your test set. Do not look at this too often! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 1486, 'TN': 15056, 'FP': 13585, 'FN': 1788, 'Accuracy': 0.518314272285759, 'Precision': 0.09859996018844137, 'Recall': 0.4538790470372633, 'desc': 'ols_test'}\n",
      "False Positive Rate:\n",
      "0.4743200307251842\n",
      "True Positive Rate:\n",
      "0.4538790470372633\n"
     ]
    }
   ],
   "source": [
    "ols_performance_test = BinaryClassificationPerformance(ols.predict(X_test), y_test, 'ols_test')\n",
    "ols_performance_test.compute_measures()\n",
    "print(ols_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(ols_performance_test.performance_measures['FP'] / ols_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(ols_performance_test.performance_measures['TP'] / ols_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2486, 'TN': 27403, 'FP': 1238, 'FN': 788, 'Accuracy': 0.9365188782704058, 'Precision': 0.667561761546724, 'Recall': 0.7593158216249236, 'desc': 'svm_test'}\n",
      "False Positive Rate:\n",
      "0.043224747739254915\n",
      "True Positive Rate:\n",
      "0.7593158216249236\n"
     ]
    }
   ],
   "source": [
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(svm_performance_test.performance_measures['FP'] / svm_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(svm_performance_test.performance_measures['TP'] / svm_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2233, 'TN': 27944, 'FP': 697, 'FN': 1041, 'Accuracy': 0.945542848190506, 'Precision': 0.7621160409556313, 'Recall': 0.6820403176542456, 'desc': 'lgs_test'}\n",
      "False Positive Rate:\n",
      "0.02433574246709263\n",
      "True Positive Rate:\n",
      "0.6820403176542456\n"
     ]
    }
   ],
   "source": [
    "lgs_performance_test = BinaryClassificationPerformance(lgs.predict(X_test), y_test, 'lgs_test')\n",
    "lgs_performance_test.compute_measures()\n",
    "print(lgs_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(lgs_performance_test.performance_measures['FP'] / lgs_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(lgs_performance_test.performance_measures['TP'] / lgs_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2355, 'TN': 27952, 'FP': 689, 'FN': 919, 'Accuracy': 0.9496161679461068, 'Precision': 0.7736530880420499, 'Recall': 0.7193036041539401, 'desc': 'lgr_test'}\n",
      "False Positive Rate:\n",
      "0.024056422610942357\n",
      "True Positive Rate:\n",
      "0.7193036041539401\n"
     ]
    }
   ],
   "source": [
    "lgr_performance_test = BinaryClassificationPerformance(lgr.predict(X2_test), y2_test, 'lgr_test')\n",
    "lgr_performance_test.compute_measures()\n",
    "print(lgr_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(lgr_performance_test.performance_measures['FP'] / lgr_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(lgr_performance_test.performance_measures['TP'] / lgr_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2704, 'TN': 25715, 'FP': 2926, 'FN': 570, 'Accuracy': 0.8904590318032273, 'Precision': 0.4802841918294849, 'Recall': 0.8259010384850336, 'desc': 'nbs_test'}\n",
      "False Positive Rate:\n",
      "0.10216123738696274\n",
      "True Positive Rate:\n",
      "0.8259010384850336\n"
     ]
    }
   ],
   "source": [
    "nbs_performance_test = BinaryClassificationPerformance(nbs.predict(X2_test), y2_test, 'nbs_test')\n",
    "nbs_performance_test.compute_measures()\n",
    "print(nbs_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(nbs_performance_test.performance_measures['FP'] / nbs_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(nbs_performance_test.performance_measures['TP'] / nbs_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 3145, 'TN': 19410, 'FP': 9231, 'FN': 129, 'Accuracy': 0.7067209775967414, 'Precision': 0.2541208791208791, 'Recall': 0.9605986560781918, 'desc': 'cnb_test'}\n",
      "True Positive Rate:\n",
      "96.05986560781918\n",
      "False Positive Rate:\n",
      "32.230019901539755\n",
      "False Negative Rate:\n",
      "3.9401343921808185\n"
     ]
    }
   ],
   "source": [
    "# Complement NB\n",
    "cnb_performance_test = BinaryClassificationPerformance(cnb.predict(X2_test), y2_test, 'cnb_test')\n",
    "cnb_performance_test.compute_measures()\n",
    "print(cnb_performance_test.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(cnb_performance_test.performance_measures['TP'] / cnb_performance_test.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(cnb_performance_test.performance_measures['FP'] / cnb_performance_test.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(cnb_performance_test.performance_measures['FN'] / cnb_performance_test.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 1963, 'TN': 28170, 'FP': 471, 'FN': 1311, 'Accuracy': 0.9441641861193796, 'Precision': 0.8064913722267871, 'Recall': 0.5995723885155773, 'desc': 'prc_test'}\n",
      "False Positive Rate:\n",
      "0.016444956530847387\n",
      "True Positive Rate:\n",
      "0.5995723885155773\n"
     ]
    }
   ],
   "source": [
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)\n",
    "print(\"False Positive Rate:\")\n",
    "print(prc_performance_test.performance_measures['FP'] / prc_performance_test.performance_measures['Neg'])\n",
    "print(\"True Positive Rate:\")\n",
    "print(prc_performance_test.performance_measures['TP'] / prc_performance_test.performance_measures['Pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators = [('nbs', nbs), ('cnb', cnb), ('rdg', rdg)]\n",
    "esb3 = VotingClassifier(estimators, voting='hard')\n",
    "esb3.fit(X2_train, y2_train)\n",
    "\n",
    "esb3_performance_train = BinaryClassificationPerformance(esb3.predict(X2_train), y2_train, 'esb3_train')\n",
    "esb3_performance_train.compute_measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2952, 'TN': 24847, 'FP': 3794, 'FN': 322, 'Accuracy': 0.8710324298919003, 'Precision': 0.43759264749481175, 'Recall': 0.9016493585827734, 'desc': 'esb3_test'}\n",
      "True Positive Rate:\n",
      "90.16493585827735\n",
      "False Positive Rate:\n",
      "13.246744177926747\n"
     ]
    }
   ],
   "source": [
    "esb3_performance_test = BinaryClassificationPerformance(esb3.predict(X2_test), y2_test, 'esb3_test')\n",
    "esb3_performance_test.compute_measures()\n",
    "print(esb3_performance_test.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(esb3_performance_test.performance_measures['TP'] / esb3_performance_test.performance_measures['Pos'] *100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(esb3_performance_test.performance_measures['FP'] / esb3_performance_test.performance_measures['Neg'] *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test = BinaryClassificationPerformance(rdg.predict(X_test), y_test, 'rdg_test')\n",
    "rdg_performance_test.compute_measures()\n",
    "print(rdg_performance_test.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test.performance_measures['TP'] / rdg_performance_test.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test.performance_measures['FP'] / rdg_performance_test.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test.performance_measures['FN'] / rdg_performance_test.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:\n",
      "97.00671960904093\n",
      "False Positive Rate:\n",
      "22.16053908732237\n",
      "False Negative Rate:\n",
      "2.9932803909590717\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_5 = BinaryClassificationPerformance(rdg_5.predict(X_test), y_test, 'rdg_test_5')\n",
    "rdg_performance_test_5.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_5.performance_measures['TP'] / rdg_performance_test_5.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_5.performance_measures['FP'] / rdg_performance_test_5.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_5.performance_measures['FN'] / rdg_performance_test_5.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test_7_5 = BinaryClassificationPerformance(rdg_7_5.predict(X_test), y_test, 'rdg_test_7_5')\n",
    "rdg_performance_test_7_5.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_7_5.performance_measures['TP'] / rdg_performance_test_7_5.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_7_5.performance_measures['FP'] / rdg_performance_test_7_5.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_7_5.performance_measures['FN'] / rdg_performance_test_7_5.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:\n",
      "95.29627367135004\n",
      "False Positive Rate:\n",
      "15.802520861701755\n",
      "False Negative Rate:\n",
      "4.703726328649969\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_10 = BinaryClassificationPerformance(rdg_10.predict(X_test), y_test, 'rdg_test_10')\n",
    "rdg_performance_test_10.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_10.performance_measures['TP'] / rdg_performance_test_10.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_10.performance_measures['FP'] / rdg_performance_test_10.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_10.performance_measures['FN'] / rdg_performance_test_10.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:\n",
      "92.79169211973122\n",
      "False Positive Rate:\n",
      "12.719527949443107\n",
      "False Negative Rate:\n",
      "7.2083078802687846\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_15 = BinaryClassificationPerformance(rdg_15.predict(X_test), y_test, 'rdg_test_15')\n",
    "rdg_performance_test_15.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_15.performance_measures['TP'] / rdg_performance_test_15.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_15.performance_measures['FP'] / rdg_performance_test_15.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_15.performance_measures['FN'] / rdg_performance_test_15.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:\n",
      "90.92852779474649\n",
      "False Positive Rate:\n",
      "10.704933486959254\n",
      "False Negative Rate:\n",
      "9.071472205253512\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_20 = BinaryClassificationPerformance(rdg_20.predict(X_test), y_test, 'rdg_test_20')\n",
    "rdg_performance_test_20.compute_measures()\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_20.performance_measures['TP'] / rdg_performance_test_20.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_20.performance_measures['FP'] / rdg_performance_test_20.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_20.performance_measures['FN'] / rdg_performance_test_20.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2910, 'TN': 25961, 'FP': 2680, 'FN': 364, 'Accuracy': 0.9046216512611625, 'Precision': 0.5205724508050089, 'Recall': 0.8888210140500916, 'desc': 'rdg_test_25'}\n",
      "True Positive Rate:\n",
      "88.88210140500917\n",
      "False Positive Rate:\n",
      "9.357215181034181\n",
      "False Negative Rate:\n",
      "11.117898594990837\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_25 = BinaryClassificationPerformance(rdg_25.predict(X_test), y_test, 'rdg_test_25')\n",
    "rdg_performance_test_25.compute_measures()\n",
    "print(rdg_performance_test_25.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_25.performance_measures['TP'] / rdg_performance_test_25.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_25.performance_measures['FP'] / rdg_performance_test_25.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_25.performance_measures['FN'] / rdg_performance_test_25.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3274, 'Neg': 28641, 'TP': 2843, 'TN': 26279, 'FP': 2362, 'FN': 431, 'Accuracy': 0.912486291712361, 'Precision': 0.5462055715658021, 'Recall': 0.8683567501527184, 'desc': 'rdg_test_30'}\n",
      "True Positive Rate:\n",
      "86.83567501527185\n",
      "False Positive Rate:\n",
      "8.246918752836843\n",
      "False Negative Rate:\n",
      "13.164324984728163\n"
     ]
    }
   ],
   "source": [
    "rdg_performance_test_30 = BinaryClassificationPerformance(rdg_30.predict(X_test), y_test, 'rdg_test_30')\n",
    "rdg_performance_test_30.compute_measures()\n",
    "print(rdg_performance_test_30.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_30.performance_measures['TP'] / rdg_performance_test_30.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_30.performance_measures['FP'] / rdg_performance_test_30.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_30.performance_measures['FN'] / rdg_performance_test_30.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test_35 = BinaryClassificationPerformance(rdg_35.predict(X_test), y_test, 'rdg_test_35')\n",
    "rdg_performance_test_35.compute_measures()\n",
    "print(rdg_performance_test_35.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_35.performance_measures['TP'] / rdg_performance_test_35.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_35.performance_measures['FP'] / rdg_performance_test_35.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_35.performance_measures['FN'] / rdg_performance_test_35.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test_40 = BinaryClassificationPerformance(rdg_40.predict(X_test), y_test, 'rdg_test_40')\n",
    "rdg_performance_test_40.compute_measures()\n",
    "print(rdg_performance_test_40.performance_measures)\n",
    "print(\"True Positive Rate:\")\n",
    "print(rdg_performance_test_40.performance_measures['TP'] / rdg_performance_test_40.performance_measures['Pos'] * 100)\n",
    "print(\"False Positive Rate:\")\n",
    "print(rdg_performance_test_40.performance_measures['FP'] / rdg_performance_test_40.performance_measures['Neg'] * 100)\n",
    "print(\"False Negative Rate:\")\n",
    "print(rdg_performance_test_40.performance_measures['FN'] / rdg_performance_test_40.performance_measures['Pos'] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf_performance_test = BinaryClassificationPerformance(rdf.predict(X_test), y_test, 'rdf_test')\n",
    "# rdf_performance_test.compute_measures()\n",
    "# print(rdf_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [rdg_performance_test, nbs_performance_test, cnb_performance_test, lgr_performance_test, esb3_performance_test]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "    \n",
    "# fits = [rdg_performance_train, rdg_performance_train_1, rdg_performance_train_2, rdg_performance_train_5, rdg_performance_train_7, rdg_performance_train_9]\n",
    "\n",
    "# for fit in fits:\n",
    "#     plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'rx')\n",
    "#     plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)    \n",
    "\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.grid(b=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rdg plot\n",
    "fits = [rdg_performance_test_5, rdg_performance_test_10, rdg_performance_test_15, rdg_performance_test_20, rdg_performance_test_25, rdg_performance_test_30]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "    \n",
    "# fits = [rdg_performance_train, rdg_performance_train_1, rdg_performance_train_2, rdg_performance_train_5, rdg_performance_train_7, rdg_performance_train_9]\n",
    "\n",
    "# for fit in fits:\n",
    "#     plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'rx')\n",
    "#     plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)    \n",
    "\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.grid(b=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">SUBMISSION</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 5 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 131072)\n",
      "Shape of HashingVectorizer char n_gram X:\n",
      "(153164, 16384)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   consCapsword_ratio  consCaps_ratio  consCaps_count  spaceswords_ratio  \\\n",
      "0            0.000000        0.000000               0           0.986111   \n",
      "1            0.076923        0.020000               1           0.923077   \n",
      "2            0.000000        0.000000               0           0.937500   \n",
      "3            0.000000        0.000000               0           0.973684   \n",
      "4            0.000000        0.000000               0           0.857143   \n",
      "5            0.000000        0.000000               0           0.937500   \n",
      "6            0.000000        0.000000               0           0.967742   \n",
      "7            0.000000        0.000000               0           0.833333   \n",
      "8            0.073394        0.014388               8           0.990826   \n",
      "9            0.000000        0.000000               0           0.975610   \n",
      "\n",
      "   spaces_ratio  spaces_count  char_count  Caps_count  Caps_ratio  word_count  \\\n",
      "0      0.193460            71         367           4    0.000003          72   \n",
      "1      0.240000            12          50           7    0.004096          13   \n",
      "2      0.277778            15          54           4    0.000794          16   \n",
      "3      0.180488            37         205           4    0.000015          38   \n",
      "4      0.146341             6          41           1    0.000116           7   \n",
      "5      0.156250            15          96           2    0.000031          16   \n",
      "6      0.170455            30         176           5    0.000040          31   \n",
      "7      0.156250             5          32           1    0.000244           6   \n",
      "8      0.194245           108         556          41    0.000431         109   \n",
      "9      0.178571            40         224           7    0.000046          41   \n",
      "\n",
      "   char_ratio  punc_count_p  punc_count_exc  punc_count_q  punc_count  \\\n",
      "0    5.097222            10               0             0          10   \n",
      "1    3.846154             1               0             0           1   \n",
      "2    3.375000             0               0             0           0   \n",
      "3    5.394737             3               0             0           3   \n",
      "4    5.857143             1               0             0           1   \n",
      "5    6.000000             2               0             0           2   \n",
      "6    5.677419             4               0             0           4   \n",
      "7    5.333333             1               0             0           1   \n",
      "8    5.100917             9               0             0           9   \n",
      "9    5.463415             0               0             0           0   \n",
      "\n",
      "   punc_ratio  Capsword_ratio  \n",
      "0    0.138889        0.194444  \n",
      "1    0.076923        0.615385  \n",
      "2    0.000000        0.250000  \n",
      "3    0.078947        0.184211  \n",
      "4    0.142857        0.285714  \n",
      "5    0.125000        0.250000  \n",
      "6    0.129032        0.290323  \n",
      "7    0.166667        0.333333  \n",
      "8    0.082569        0.458716  \n",
      "9    0.000000        0.170732  \n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 147473)\n",
      "(153164, 147473)\n",
      "Shape of X_test for submission:\n",
      "(153164, 147473)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data, X_test_submission = process_raw_data(fn='/Users/Charles/Desktop/ML/A1/toxiccomments_test.csv', my_random_seed=36, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 5 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 16384)\n",
      "Shape of HashingVectorizer char n_gram X:\n",
      "(153164, 16384)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   consCaps_count  consCaps_ratio  consCapsword_ratio  punc_q_ratio  \\\n",
      "0               0        0.000000            0.000000      0.009009   \n",
      "1               1        0.020000            0.076923      0.047619   \n",
      "2               0        0.000000            0.000000      0.090909   \n",
      "3               0        0.000000            0.000000      0.024390   \n",
      "4               0        0.000000            0.000000      0.090909   \n",
      "5               0        0.000000            0.000000      0.047619   \n",
      "6               0        0.000000            0.000000      0.019608   \n",
      "7               0        0.000000            0.000000      0.090909   \n",
      "8               8        0.014388            0.073394      0.009901   \n",
      "9               0        0.000000            0.000000      0.019608   \n",
      "\n",
      "   punc_exc_ratio  punc_count_s  punc_count_a  punc_count_c  \\\n",
      "0        0.009009             0             0             1   \n",
      "1        0.047619             0             0             1   \n",
      "2        0.090909             0             1             0   \n",
      "3        0.024390             0             0             1   \n",
      "4        0.090909             0             0             0   \n",
      "5        0.047619             0             0             0   \n",
      "6        0.019608             0             0             1   \n",
      "7        0.090909             0             0             0   \n",
      "8        0.009901             0             0             1   \n",
      "9        0.019608             0             0             5   \n",
      "\n",
      "   spaceswords_ratio  spaces_ratio  ...  Caps_count  Caps_ratio  word_count  \\\n",
      "0           0.986111      0.193460  ...           4    0.000003          72   \n",
      "1           0.923077      0.240000  ...           7    0.004096          13   \n",
      "2           0.937500      0.277778  ...           4    0.000794          16   \n",
      "3           0.973684      0.180488  ...           4    0.000015          38   \n",
      "4           0.857143      0.146341  ...           1    0.000116           7   \n",
      "5           0.937500      0.156250  ...           2    0.000031          16   \n",
      "6           0.967742      0.170455  ...           5    0.000040          31   \n",
      "7           0.833333      0.156250  ...           1    0.000244           6   \n",
      "8           0.990826      0.194245  ...          41    0.000431         109   \n",
      "9           0.975610      0.178571  ...           7    0.000046          41   \n",
      "\n",
      "   char_ratio  punc_count_p  punc_count_exc  punc_count_q  punc_count  \\\n",
      "0    5.097222            10               0             0          11   \n",
      "1    3.846154             1               0             0           2   \n",
      "2    3.375000             0               0             0           1   \n",
      "3    5.394737             3               0             0           4   \n",
      "4    5.857143             1               0             0           1   \n",
      "5    6.000000             2               0             0           2   \n",
      "6    5.677419             4               0             0           5   \n",
      "7    5.333333             1               0             0           1   \n",
      "8    5.100917             9               0             0          10   \n",
      "9    5.463415             0               0             0           5   \n",
      "\n",
      "   punc_ratio  Capsword_ratio  \n",
      "0    0.152778        0.208333  \n",
      "1    0.153846        0.692308  \n",
      "2    0.062500        0.312500  \n",
      "3    0.105263        0.210526  \n",
      "4    0.142857        0.285714  \n",
      "5    0.125000        0.250000  \n",
      "6    0.161290        0.322581  \n",
      "7    0.166667        0.333333  \n",
      "8    0.091743        0.467890  \n",
      "9    0.121951        0.292683  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 32790)\n",
      "(153164, 32790)\n",
      "Shape of X_test for submission:\n",
      "(153164, 32790)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data2, X2_test_submission = process_raw_data2(fn='/Users/Charles/Desktop/ML/A1/toxiccomments_test.csv', my_random_seed=36, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2 HashingV passed through respective tfidf transformer and then hstacked with quantfeat: AttributeError: lower not found\n",
    "# for 2 HashingV hstacked and passed through tfidf transformer: TypeError: 'coo_matrix' object is not subscriptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a <span style=\"color:red\">*single*</span> model for your submission. In this code, I am choosing the Ordinary Least Squares model fit, which is in the `ols` object. But you should choose the model that is performing the best for you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction_rdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00084da5d4ead7aa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0009734200a85047</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00097b6214686db5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0009aef4bd9e1697</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000a02d807ae0254</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000a6c6d4e89b9bc</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000bafe2080bba82</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000bf0a9894b2807</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>000c50dceb1eed2b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>000c9b92318552d1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>000ce41d86f2b886</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>000cf60dbaed8c02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>000d4f120d5a7303</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>000d60becb7d1a67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>000fc381d4895598</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>000ff37cf57ab537</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>001068b809feee6b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0011c58fcfd6bf91</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0011cefc680993ba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0011ef6aa33d42e6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0012706ac77a7b37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0012bb72f20ae971</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0012bbcbd6958302</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>00137446b1aec28c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0013a435effa29bd</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0013be435187e84f</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0013fed3aeae76b7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>001411adf8f1dd82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  prediction_rdg\n",
       "0   00001cee341fdb12            True\n",
       "1   0000247867823ef7           False\n",
       "2   00013b17ad220c46           False\n",
       "3   00017563c3f7919a           False\n",
       "4   00017695ad8997eb           False\n",
       "5   0001ea8717f6de06           False\n",
       "6   00024115d4cbde0f           False\n",
       "7   000247e83dcc1211            True\n",
       "8   00025358d4737918           False\n",
       "9   00026d1092fe71cc           False\n",
       "10  0002eadc3b301559           False\n",
       "11  0002f87b16116a7f           False\n",
       "12  0003806b11932181           False\n",
       "13  0003e1cccfd5a40a           False\n",
       "14  00059ace3e3e9a53           False\n",
       "15  000634272d0d44eb           False\n",
       "16  000663aff0fffc80           False\n",
       "17  000689dd34e20979           False\n",
       "18  000834769115370c           False\n",
       "19  000844b52dee5f3f           False\n",
       "20  00084da5d4ead7aa           False\n",
       "21  00091c35fa9d0465            True\n",
       "22  000968ce11f5ee34            True\n",
       "23  0009734200a85047           False\n",
       "24  00097b6214686db5            True\n",
       "25  0009aef4bd9e1697           False\n",
       "26  000a02d807ae0254           False\n",
       "27  000a6c6d4e89b9bc            True\n",
       "28  000bafe2080bba82            True\n",
       "29  000bf0a9894b2807           False\n",
       "30  000c50dceb1eed2b           False\n",
       "31  000c9b92318552d1           False\n",
       "32  000ce41d86f2b886           False\n",
       "33  000cf60dbaed8c02           False\n",
       "34  000d4f120d5a7303           False\n",
       "35  000d60becb7d1a67           False\n",
       "36  000fc381d4895598           False\n",
       "37  000ff37cf57ab537           False\n",
       "38  001068b809feee6b            True\n",
       "39  0011c58fcfd6bf91           False\n",
       "40  0011cefc680993ba           False\n",
       "41  0011ef6aa33d42e6           False\n",
       "42  0012706ac77a7b37           False\n",
       "43  0012bb72f20ae971           False\n",
       "44  0012bbcbd6958302           False\n",
       "45  00137446b1aec28c           False\n",
       "46  0013a435effa29bd           False\n",
       "47  0013be435187e84f           False\n",
       "48  0013fed3aeae76b7            True\n",
       "49  001411adf8f1dd82           False"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission2 = pd.DataFrame(raw_data2[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission2[\"prediction_esb\"] = esb3.predict(X2_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "# print(my_submission['prediction'].mean())\n",
    "\n",
    "my_submission2[\"prediction_nbs\"] = nbs.predict(X2_test_submission)\n",
    "\n",
    "my_submission2[\"prediction_cnb\"] = cnb.predict(X2_test_submission)\n",
    "\n",
    "my_submission2[\"prediction_lgr\"] = lgr.predict(X2_test_submission)\n",
    "\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "\n",
    "my_submission[\"prediction_rdg\"] = rdg.predict(X_test_submission)\n",
    "\n",
    "# how to create weighted ensemble voting here\n",
    "\n",
    "weighted_sum = weighted\n",
    "conditional = if weighted sum>0, true\n",
    "my_submission_new = new dataframe\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.head(50)\n",
    "my_submission.to_csv('/Users/Charles/Desktop/ML/A1/toxiccomments_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_submission3 = hstack([my_submission, my_submission2])\n",
    "my_submission2.head(50)\n",
    "my_submission2.to_csv('/Users/Charles/Desktop/ML/A1/toxiccomments_ensemble2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3325455067770494\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = esb3.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29366561332950303\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = rdg_30.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Caps_count</th>\n",
       "      <th>Caps_ratio</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_ratio</th>\n",
       "      <th>punc_count_p</th>\n",
       "      <th>punc_count_exc</th>\n",
       "      <th>punc_count_q</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>punc_ratio</th>\n",
       "      <th>Capsword_ratio</th>\n",
       "      <th>spaces_count</th>\n",
       "      <th>spaces_ratio</th>\n",
       "      <th>spaceswords_ratio</th>\n",
       "      <th>consCaps_count</th>\n",
       "      <th>consCaps_ratio</th>\n",
       "      <th>consCapsword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>367</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>72</td>\n",
       "      <td>5.097222</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>71</td>\n",
       "      <td>0.193460</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>13</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>12</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>16</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>205</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>38</td>\n",
       "      <td>5.394737</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>37</td>\n",
       "      <td>0.180488</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>7</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "   char_count  Caps_count  Caps_ratio  word_count  char_ratio  punc_count_p  \\\n",
       "0         367           4    0.000003          72    5.097222            10   \n",
       "1          50           7    0.004096          13    3.846154             1   \n",
       "2          54           4    0.000794          16    3.375000             0   \n",
       "3         205           4    0.000015          38    5.394737             3   \n",
       "4          41           1    0.000116           7    5.857143             1   \n",
       "\n",
       "   punc_count_exc  punc_count_q  punc_count  punc_ratio  Capsword_ratio  \\\n",
       "0               0             0          10    0.138889        0.194444   \n",
       "1               0             0           1    0.076923        0.615385   \n",
       "2               0             0           0    0.000000        0.250000   \n",
       "3               0             0           3    0.078947        0.184211   \n",
       "4               0             0           1    0.142857        0.285714   \n",
       "\n",
       "   spaces_count  spaces_ratio  spaceswords_ratio  consCaps_count  \\\n",
       "0            71      0.193460           0.986111               0   \n",
       "1            12      0.240000           0.923077               1   \n",
       "2            15      0.277778           0.937500               0   \n",
       "3            37      0.180488           0.973684               0   \n",
       "4             6      0.146341           0.857143               0   \n",
       "\n",
       "   consCaps_ratio  consCapsword_ratio  \n",
       "0            0.00            0.000000  \n",
       "1            0.02            0.076923  \n",
       "2            0.00            0.000000  \n",
       "3            0.00            0.000000  \n",
       "4            0.00            0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  00001cee341fdb12        True\n",
       "1  0000247867823ef7       False\n",
       "2  00013b17ad220c46       False\n",
       "3  00017563c3f7919a       False\n",
       "4  00017695ad8997eb       False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv('/Users/Charles/Desktop/ML/A1/toxiccomments_4th_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Canvas: 1) the CSV file that was written in the previous cell and 2) the url to the repository (GitHub or other) that contains your code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
